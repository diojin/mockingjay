#                 Scala for the Impatient ###                   Cay S. Horstmann######                    Second printing, June 2013___Indexes---* [1. The Basics](#basics)  - [The apply Method](#the-apply-method)* [2. Control Structures and Functions](#control-structures-and-functions)  - [for loop](#for-loop)  - [for comprehension](#for-comprehension)  - [function](#function)    + [Default and Named Arguments](#default-and-named-arguments)    + [Variable Arguments](#variable-arguments)  - [procedure](#procedure)  - [Lazy Values](#lazy-values)  - [Exceptions](#exceptions)* [3. Working with Arrays](#working-with-arrays)  - [Range](#range)  - [for if yield or filter map](#for-if-yield-or-filter-map)  - [array sorting](#array-sorting)  - [multidimensional arrays](#multidimensional-arrays)  - [Interoperating with Java](#interoperating-with-java)* [4. Maps and Tuples](#maps-and-tuples)  - [pair](#pair)  - [Interoperating with Java for map](#interoperating-with-Java-for-map)  - [Tuples](#tuples)  - [Tuples to Map](#tuples-to-map)* [5. Classes](#classes)  - [Object-Private Fields](#object-private-fields)  - [auxiliary constructor](#auxiliary-constructor)  - [primary constructor](#primary-constructor)* [6. Objects](#objects)  - [Companion Objects](#companion-objects)  - [The apply Method](#the-apply-method-1)  - [Application Objects](#application-objects)  - [Enumerations](#enumerations)* [7. Packages and Imports](#packages-and-imports)  - [Scope Rules](#scope-rules)  - [Chained Package Clauses](#chained-package-clauses)  - [Top-of-File Notation](#top-of-file-notation)  - [Package Objects](#package-objects)  - [Renaming and Hiding Members](#renaming-and-hiding-members)* [8. Inheritance](#inheritance)  - [Type Checks and Casts](#type-checks-and-casts)  - [Overriding Fields](#overriding-fields)  - [Anonymous Subclasses](#anonymous-subclasses)  - [Abstract Fields](#abstract-fields)  - [The Scala Inheritance Hierarchy](#the-scala-inheritance-hierarchy)* [9. Files and Regular Expressions](#files-and-regular-expressions)  - [Process Control](#process-control)  - [Regular Expressions](#regular-expressions)* [10. Traits](#traits)  - [Objects with Traits](#objects-with-traits)  - [Fields in Traits](#fields-in-traits)  - [Trait Construction Order](#trait-construction-order)  - [linearization of the class](#linearization-of-the-class)  - [Initializing Trait Fields](#initializing-trait-fields)  - [Self Types](#self-types)* [11. Operators](#operators)  - [The unapplySeq Method](#the-unapplyseq-method)* [12. Higher-Order Functions](#higher-order-functions)  - [Anonymous Functions](#anonymous-functions)  - [Functions with Function Parameters](#functions-with-function-parameters)  - [Closures](#closures)  - [SAM Conversions](#sam-conversions)  - [Currying](#currying)  - [model a sequence of statements as a function](#model-a-sequence-of-statements-as-a-function)* [13. Collections](#collections)  - [Lists](#scala-lists)  - [Mapping a Function](#mapping-a-function)  - [Reducing, Folding, and Scanning](#reducing-folding-and-scanning)  - [Zipping](#zipping)  - [Streams](#scala-streams)  - [Lazy Views](#lazy-views)  - [Threadsafe Collections](#threadsafe-collections)* [14. Pattern Matching and Case Classes](#pattern-matching-and-case-classes)  - [Type Patterns](#type-patterns)  - [Case Classes](#case-classes)  - [The copy Method and Named Parameters](#the-copy-method-and-named-parameters)  - [Infix Notation in case Clauses](#infix-notation-in-case-clauses)  - [Matching Nested Structures](#matching-nested-structures)  - [Sealed Classes](#sealed-classes)  - [The Option Type](#the-option-Type)  - [Partial Functions](#partial-functions)* [15. Annotations](#annotations)  - [Annotations for Optimizations](#annotations-for-optimizations)  - [Specialization for Primitive Types](#specialization-for-primitive-types)* [16. XML Processing](#xml-processing)  - [XML Literals](#xml-literals)  - [Embedded Expressions](#embedded-expressions)  - [XPath-like Expressions](#xpath-like-expressions)  - [Modifying Elements and Attributes](#modifying-elements-and-attributes)  - [Transforming XML](#transforming-xml)* [17. Type Parameters](#type-parameters)  - [The Manifest Context Bound](#the-manifest-context-bound)  - [Type Constraints](#type-constraints)  - [Variance](#scala-variance)  - [Invariant](#scala-invariant)  - [Wildcards](#scala-wildcards)* [18. Advanced Types](#advaned-types)  - [Singleton Types](#singleton-types)  - [Type projection](#type-projection)  - [Paths](#scala-paths)  - [Type Aliases](#type-aliases)  - [Structural Types](#structural-types)  - [Compound Types](#compound-types)  - [Existential Types](#existential-types)  - [Self Types](#self-types)  - [Abstract Types](#abstract-types)  - [Higher-Kinded Types](#higher-kinded-types)* [19. Parsing](#parsing)  - [Left Recursion](#left-recursion)  - [Packrat Parsers](#packrat-parsers)* [20. Actors](#actors)  - [Channels](#channels)  - [Linking Actors](#linking-actors)  - [Designing with Actors](#designing-with-actors)* [21. Implicits](#implicits)  - [Implicit Parameters](#implicit-parameters)  - [Context Bounds](#context-bounds)  - [The @implicitNotFound Annotation](#the-implicitnotfound-annotation)* [22. Delimited Continuations](#delimited-continuations)Basics---Scala is statically typed, enabling the compiler to find errorsAs you can see, the Scala interpreter reads an expression, evaluates it, prints it, and reads the next expression. This is called the read-eval-print loop, or **REPL**.  Technically speaking, the scala program is not an interpreter. `Behind the scenes, your input is quickly compiled into bytecode, and the bytecode is executed by the Java virtual machine.` For that reason, most Scala programmers prefer to call it “theREPL”.__Scala interpreter hotkeys:__  * tab completion for method, hit the Tab key * paste mode  If you want to paste a block of code into the REPL without worrying about its nearsightedness, use paste mode. Type  :paste  Then paste in the code block and type Ctrl+K. The REPL will then analyze the block in its entirety. Ctrl+D to finish the pasteA value declared with val is actually a constant—you can’t change its contents  To declare a variable whose contents can vary, use a var  Note that you need not specify the type of a value or variable. It is inferred from the type of the expression with which youinitialize it. (It is an error to declare a value or variable without initializing it.)  However, you can specify the type if necessary. For example,  ```scalaval greeting: String = nullval greeting: Any = "Hello"````In Scala, you use methods, not casts, to convert between numeric types. For example, 99.44.toInt is 99, and 99.toChar is 'c'.`  PS: 2 exceptions  1. way 1  ```scalaMessageFormat.format("the answer is {0} to {1}", "everything", 42.asInstanceOf[AnyRef]))  ```2. another possible example of type convert  ```scala    println(recursiveSum(1 to 10:_*))    println(recursiveSum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))    def recursiveSum(args: Int*):Int = {      if ( args.length == 0 ){        0      }else{        args(0) + recursiveSum(args.tail:_*)      }    }```Like Java, Scala has `7 numeric types: Byte, Char, Short, Int, Long, Float, and Double, and a Boolean type.` However, unlike Java, these types are classes. There is no distinction between primitive types and class types in Scala. You can invoke methods on numbers, for example:  ```scala1.to(10) // Yields Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)```Scala relies on the underlying java.lang.String class for strings. However, it augments that class with well over a hundred operations in the **StringOps** class.  ```scala"Hello".intersect("World") // Yields "lo"```In this expression, the java.lang.String object "Hello" is `implicitly converted to a StringOps object`, and then the intersect method of the **StringOps** class is applied.Similarly, there are classes **RichInt**, **RichDouble**, **RichChar**, and so on.Finally, there are classes **BigInt** and **BigDecimal** for computations with an arbitrary (but finite) number of digits. These are backed by the java.math.BigInteger and java.math.BigDecimal classes, but, as you will see in the next section, they are much more convenient because you `can use them with the usual mathematical operators.`  ```scalaval x: BigInt = 1234567890x * x * x // Yields 1881676371789154860897069000// That’s much better than Java, where you would have had to call x.multiply(x).multiply(x).```The + - * / % operators do their usual job, as do the bit operators & | ^ >> <<. There is just one surprising aspect: These operators are actually methods. For example,  `a + b`  is a shorthand for  `a.+(b)`  Here, + is the name of the method. Scala has no silly prejudice against non-alphanumeric characters in method names. You can define methods with just about any symbols for names.In general, you can write  `a method b`  as a shorthand for  `a.method(b)`  where method is a method with two parameters (one implicit, one explicit).There is one notable difference between Scala and Java or C++. `Scala does not have ++ or -- operators`. Instead, simply use +=1 or -=1:`Scala allows you to define operators`To use a package that starts with scala., you can omit the scala prefix. For example, import math._ is equivalent to import scala.math._, and math.sqrt(2) is the same as scala.math.sqrt(2).`Scala doesn’t have static methods`, but it has a similar feature, called __singleton objects__, which we will discuss in detail in Chapter 6. Often, a class has a __companion object__ whose methods act just like static methods do in Java. For example, the BigInt companion object to the BigInt class has a method probablePrime that generates a random prime number with a givennumber of bits:  ```scalaBigInt.probablePrime(100, scala.util.Random)```Note that the call BigInt.probablePrime is similar to a static method call in JavaHere, Random is a singleton random number generator object, defined in the scala.util package. This is one of the few situations where a singleton object is better than a class. In Java, it is a common error to construct a new java.util.Random object for each random number.Scala methods without parameters often don’t use parentheses. For example, the API of the StringOps class shows a method distinct, without (), to get the distinct letters in a string. You call it as   ```scala"Hello".distinct```The rule of thumb is that a parameterless method that doesn’t modify the object has no parentheses.#### The apply Method[Back To Index](#indexes)   In Scala, it is common to use a syntax that looks like a function call. For example, if s is a string, then s(i) is the ith character of the string. (In C++, you would write s[i]; in Java, s.charAt(i).) Try it out in the REPL:  ```scala"Hello"(4) // Yields 'o'````You can think of this as an overloaded form of the () operator. It is implemented as a method with the name apply.`  For example, in the documentation of the StringOps class, you will find a method  ```scaladef apply(n: Int): Char```That is,   ```scala"Hello"(4)// is a shortcut for "Hello".apply(4) ```When you look at the documentation for the BigInt companion object, you will see apply methods that let you convert strings or numbers to BigInt objects.   For example,  ```scala// the call BigInt("1234567890") // is a shortcut for BigInt.apply("1234567890") ```It yields a new BigInt object, `without having to use new``Using the apply method of a companion object is a common Scala idiom for constructing objects.`  For example,  ```scalaArray(1, 4, 9, 16)```returns an array, thanks to the apply method of the Array companion object.`A method tagged as implicit is an automatic conversion.`  For example, the BigInt object has conversions from int and long to BigInt that are automatically called when needed. `Methods can have functions as parameters.`  For example, the count method in StringOps requires a function that returns true or false for a Char, specifying which characters should be counted:```scaladef count(p: (Char) => Boolean) : Int```You supply a function, often in a very compact notation, when you call the method. As an example, the call **s.count(_.isUpper)** counts the number of uppercase characters. Control Structures and Functions---You will encounter a fundamental difference between Scala and other programming languages. In Java or C++, we differentiate between expressions (such as 3 + 4) and statements (for example, an if statement).   `An expression has a value; a statement carries out an action. In Scala, almost all constructs have values.`  Here are the highlights of this chapter:  * `An if expression has a value`* `A block has a value—the value of its last expression`* The Scala for loop is like an “enhanced” Java for loop* Semicolons are (mostly) optional* `The void type is Unit`* Avoid using return in a function* Beware of missing = in a function definition* `Exceptions work just like in Java or C++, but you use a “pattern matching” syntax for catch`* `Scala has no checked exceptions`in Scala, an if/else has a value, namely the value of the expression that follows the if or else.  ```scalaval s = if (x > 0) 1 else -1```The Scala if/else combines the if/else and ?: constructs that are separate in Java and C++.The type of a mixed-type expression, such as  ```scalaif (x > 0) "positive" else -1```is the common supertype of both branches. In this example, one branch is a java.lang.String, and the other an Int. Their common supertype is called Any. If the else part is omitted, for example in  if(x>0) 1  then it is possible that the if statement yields no value. However, in Scala, every expression is supposed to have some value. `This is finessed by introducing a class Unit that has one value, written as ().` The if statement without an else is equivalent to  ```scalaif (x>0) 1 else ()````Think of () as a placeholder for “no useful value,” and think of Unit as the analog of void in Java or C++.`  Technically speaking, void has no value whereas Unit has one value that signifies “no value”. If you are so inclined, you can ponder the difference between an empty wallet and a wallet with a bill labeled “no dollars”.`Scala has no switch statement`, but it has a much more powerful pattern matching mechanismHowever, if you want to have more than one statement on a single line, you need to separate them with semicolons.In Scala, a { } block contains a sequence of expressions, and the result is also an expression. The value of the block is the value of the last expression.This feature can be useful if the initialization of a val takes more than one step. For example,  ```scalaval distance = { val dx = x - x0; val dy = y - y0; sqrt(dx * dx + dy * dy) }````In Scala, assignments have no value—or, strictly speaking, they have a value of type Unit.`A block that ends with an assignment statement, such as {r=r*n; n-=1} has a Unit value.You can read a line of input from the console with the `readLine` function. To read a numeric, Boolean, or character value, use readInt, readDouble, readByte, readShort, readLong, readFloat, readBoolean, or readChar. The readLine method, but not the other ones, takes a prompt string:  ```scalaval name = readLine("Your name: ")print("Your age: ")val age = readInt()printf("Hello, %s! Next year, you will be %d.\n", name, age + 1)```Notice: read*() methods are all deprecated after 2.11Scala has the same `while` and `do` loops as Java and C++. #### for loop```scalafor(i <- 1 to n)     r=r*i```The call 1 to n returns a Range of the numbers from 1 to n (inclusive).   The construct for **(i <- expr)** makes the variable i traverse all values of the expression to the right of the <-. Exactly how that traversal works depends on the type of the expression. For a Scala collection, such as a Range, the loop makes i assume each value in turn.  There is no val or var before the variable in the for loop. `The type of the variable is the element type of the collection`. The scope of the loop variable extends until the end of the loop.When traversing a string or array, you often need a range from 0 to n – 1. In that case, use the until method instead of the to method. It returns a range that doesn’t include the upper bound.```scalaval s = "Hello"var sum = 0for (i <- 0 until s.length) // Last value for i is s.length - 1  sum += s(i)```In this example, there is actually no need to use indexes. You can directly loop over the characters:  ```scalavar sum = 0for (ch <- "Hello")     sum += chprintln(sum)````In Scala, loops are not used as often as in other languages. As you will see in Chapter 12, you can often process the values in a sequence by applying a function to all of them, which can be done with a single method call.``Scala has no break or continue statements to break out of a loop`.   What to do if you need a break? Here are a few options:   1. Use a Boolean control variable instead.2. Use nested functions—you can return from the middle of a function.3. Use the break method in the Breaks object:```scalaimport scala.util.control.Breaks._breakable {  for (...) {    if (...) break; // Exits the breakable block ...   } }````Here, the control transfer is done by throwing and catching an exception, so you should avoid this mechanism when time is of the essence.`#### for comprehensionYou can have multiple generators of the form variable <- expression. Separate them by semicolons. For example,  ```scalafor (i <- 1 to 3; j <- 1 to 3) print((10 * i + j) + " ")// Prints 11 12 13 21 22 23 31 32 33```Each generator can have a guard, a Boolean condition preceded by if:  ```scalafor (i <- 1 to 3; j <- 1 to 3 if i != j) print((10 * i + j) + " ")// Prints 12 13 21 23 31 32```When the body of the for loop starts with yield, then the loop constructs a collection of values, one for each iteration: ```scalafor(i<-1 to 10) yield i%3    // Yields Vector(1, 2, 0, 1, 2, 0, 1, 2, 0, 1)```This type of loop is called a **for comprehension**.`The generated collection is compatible with the first generator.````scalafor (c <- "Hello"; i <- 0 to 1) yield (c + i).toChar     // Yields "HIeflmlmop"for (i <- 0 to 1; c <- "Hello") yield (c + i).toChar    // Yields Vector('H', 'e', 'l', 'l', 'o', 'I', 'f', 'm', 'm', 'p')```#### functionScala has functions in addition to methods. A method operates on an object, but a function doesn’t. C++ has functions as well, but in Java, you have to imitate them with static methods.  While there is nothing wrong with using return in a named function (except the waste of seven keystrokes), it is a good idea to get used to life without return. Pretty soon, you will be using lots of anonymous functions, and there, return doesn’t return a value to the caller. It breaks out to the enclosing named function. **Think of return as a kind of break statement for functions, and only use it when you want that breakout functionality.**You must specify the types of all parameters. However, as long as the function is not recursive, you need not specify the return type. The Scala compiler determines the return type from the type of the expression to the right of the = symbol.  ```scaladef fac(n: Int): Int = if (n <= 0) 1 else n * fac(n - 1)```##### Default and Named ArgumentsYou can provide default arguments for functions that are used when you don’t specify explicit values. For example,  ```scaladef decorate(str: String, left: String = "[", right: String = "]") =left + str + rightprintln(decorate("Hello"))```__Named arguments__  You can also specify the parameter names when you supply the arguments. For example,   ```scaladecorate(left = "<<<", str = "Hello", right = ">>>")// The result is "<<<Hello>>>".```##### Variable ArgumentsThe function receives a single parameter of type **Seq**  ```scaladef sum(args: Int*) = {  var result = 0  for (arg <- args) result += arg  result}println(sum(1, 4, 9, 16, 25))```__argument sequence__  ```scalaprintln( recursiveSum(1, 2, 3, 4, 5) )    println( recursiveSum(1 to 5:_*))def recursiveSum(args: Int*) : Int = {  if ( args.length== 0 )     0  else    args.head + recursiveSum(args.tail:_*)}```Here, the head of a sequence is its initial element, and tail is a sequence of all other elements. `That’s again a Seq, and we have to use : _* to convert it to an argument sequence`.  Generally, the : notation is used for **type ascription**, forcing the compiler to see a value as some particular type. This is not quite the same as casting._*,  It "splats" the sequence. This doesn't have a cutesy-name in the SLS, but here are the details. The important thing to get is that it changes how Scala binds the arguments to the method with repeated parameters. That's scala syntax for exploding subclasses of Seq[T].`When you call a Java method with variable (number of )arguments of type Object, such as PrintStream.printf or MessageFormat.format, you need to convert any primitive types by hand.` For example,```scalaval str = MessageFormat.format("The answer to {0} is {1}", "everything", 42.asInstanceOf[AnyRef])```This is the case for any Object parameter, but I mention it here because it is most common with **varargs** methods.#### procedureScala has a special notation for a function that returns no value. If the function body is enclosed in braces `without a preceding = symbol, then the return type is Unit.` Such a function is called a procedure. A procedure returns no value, and you only call it for its side effect.Some people (not me) dislike this concise syntax for procedures and suggest that you always use an explicit return type of Unit:  ```scaladef box(s : String): Unit = {	//...}```The concise procedure syntax can be a surprise for Java and C++ programmers. It is a common error to accidentally omit the = in a function definition. You then get an error message at the point where the function is called, and you are told that Unit is not acceptable at that location.#### Lazy ValuesWhen a val is declared as __lazy__, its initialization is deferred until it is accessed for the first time. For example,  ```scalalazy val words = scala.io.Source.fromFile("/usr/share/dict/words").mkString```Lazy values are useful to delay costly initialization statements. They can also deal with other initialization issues, such as circular dependencies. Moreover, `they are essential for developing lazy data structures—see Section 13.13, “Streams”`You can think of lazy values as halfway between val and def. Compare  ```scalaval words = scala.io.Source.fromFile("/usr/share/dict/words").mkString// Evaluated as soon as words is definedlazy val words = scala.io.Source.fromFile("/usr/share/dict/words").mkString// Evaluated the first time words is useddef words = scala.io.Source.fromFile("/usr/share/dict/words").mkString// Evaluated every time words is used````Laziness is not cost-free. Every time a lazy value is accessed, a method is called that checks, in a threadsafe manner, whether the value has already been initialized.`#### ExceptionsScala exceptions work the same way as in Java or C++.  As in Java, the objects that you throw need to belong to a subclass of java.lang.Throwable. However, unlike Java, Scala has `no “checked” exceptions`—you never have to declare that a function or method might throw an exception.`A throw expression has the special type Nothing. That is useful in if/else expressions. If one branch has type Nothing, the type of the if/else expression is the type of the other branch.`   For example, consider  ```scalaif (x >= 0) {      sqrt(x)} else throw new IllegalArgumentException("x should not be negative")```The first branch has type Double, the second has type `Nothing`. Therefore, the if/else expression also has type Double.The syntax for catching exceptions is modeled after the pattern matching syntax (see Chapter 14).```scala    var io:InputStream = null    try{          io = new URL("http://horstmann.com/fred-tiny.gif").openStream()    }catch{      case _: MalformedURLException => println("Bad URL: " + io.toString())      case ex: FileNotFoundException => ex.printStackTrace()      case ex: IOException => ex.printStackTrace()    }finally{      if ( io != null ){        io.close      }    } ```As in Java or C++, the more general exception types should come after the more specific ones.Note that you can use _ for the variable name if you don’t need it.The try/finally statement lets you dispose of a resource whether or not an exception has occurred. For example:```scala    var in = new URL("http://horstmann.com/fred.gif").openStream()    try {      process(in)    } finally {      in.close()    }```The finally clause is executed whether or not the process function throws an exception. The reader is always closed.  It is possible to combine them into a single try/catch/finally statement:try { ... } catch { ... } finally { ... }Working with Arrays---* Use an **Array** if the length is fixed, and an **ArrayBuffer** if the length can vary.  * Don’t use new when supplying initial values.  * Use () to access elements.  * Use for (elem <- arr) to traverse the elements.  * `Use for (elem <- arr if . . . ) . . . yield . . . to transform into a new array`  * Scala and Java arrays are interoperable; with ArrayBuffer, use **scala.collection.JavaConversions**.```scala// A string array with ten elements, all initialized with nullval a = new Array[String](10)val s = Array("Hello", "World")s(0) = "Goodbye"// Array("Goodbye", "World")````Inside the JVM, a Scala Array is implemented as a Java array.````scalaimport scala.collection.mutable.ArrayBufferval b = ArrayBuffer[Int]()// Or new ArrayBuffer[Int]// Or new ArrayBuffer[Int]()// An empty array buffer, ready to hold integersb += 1// ArrayBuffer(1)// Add an element at the end with +=b += (1, 2, 3, 5)// ArrayBuffer(1, 1, 2, 3, 5)// Add multiple elements at the end by enclosing them in parenthesesb ++= Array(8, 13, 21)// ArrayBuffer(1, 1, 2, 3, 5, 8, 13, 21)b ++= 22 to 23// ArrayBuffer(1, 1, 2, 3, 5, 8, 13, 21, 22, 23)// You can append any collection with the ++= operator//    b += 4 to 10        // failed due to type mismatch//    b += Array(11, 12)  // failed due to type mismatchb.trimEnd(5)// ArrayBuffer(1, 1, 2, 3, 5)// Removes the last five elements```Adding or removing elements at the end of an array buffer is an efficient (“amortized constant time”) operation. You can also insert and remove elements at an arbitrary location, but those operations are not as efficient—all elements after that location must be shifted.  ```scalaval b = ArrayBuffer(1, 1, 2, 3, 5)b.insert(2, 10, 11, 12)// ArrayBuffer(1, 1, 10, 11, 12, 2, 3, 5)b.remove(2)// ArrayBuffer(1, 1, 11, 12, 2, 3, 5)b.remove(2, 2)// ArrayBuffer(1, 1, 2, 3, 5)```Sometimes, you want to build up an Array, but you don’t yet know how many elements you will need. In that case, first make anarray buffer, then call  **b.toArray**  Conversely, call **a.toBuffer** to convert the array a to an array buffer.It is very easy to take an array (or array buffer) and transform it in some way. Such transformations `don’t modify the original array, but they yield a new one.`#### Range```scalaprintln(1 to 10)            // Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)println(1 until 10)         // Range(1, 2, 3, 4, 5, 6, 7, 8, 9)println((1 to 10).reverse)  // Range(10, 9, 8, 7, 6, 5, 4, 3, 2, 1)// every second elementprintln( 1 to (10, 2) )     // Range(1, 3, 5, 7, 9)```#### for if yield or filter mapOftentimes, when you traverse a collection, you only want to process the elements that match a particular condition. This is achieved with a guard: an if inside the for. Here we double every even element, dropping the odd ones:  ```scalafor (elem <- a if elem % 2 == 0) yield 2 * elem```Alternatively, you could write```scalaa.filter(_ % 2 == 0).map(2 * _)a filter { _ % 2 == 0 } map { 2 * _ }a filter(_ % 2 == 0) map(2 * _)b.filter { _ % 2 == 0 }.map { 2 * _ }```Some programmers with experience in functional programming prefer filter and map to guards and yield. That’s just a matter of style—the for loop does exactly the same work. Use whichever you find easier.  `Keep in mind that the result is a new collection—the original collection is not affected`.```scala  val input = ArrayBuffer(1, 2, 3, 4, 5, 6)// there is no ++ operator in scala var latch = new AtomicInteger(-1);val res4 = for ( i <- input if latch.incrementAndGet() > 0 ) yield iprintln(res4)  // ArrayBuffer(2, 3, 4, 5, 6)```An example, Given an array buffer of integers, we want to remove all but the first negative number.  ```scala// efficient oneval dataset = ArrayBuffer(1, 2, -3, 4, -5, 6, 7, -9 )println("input array:" + dataset)var first = trueval indexSet = for ( i <- 0 until dataset.length if first || dataset(i) >= 0) yield {  if ( dataset(i) < 0 ) first = false ; i     }for ( i <- 0 until indexSet.length ) {  dataset(i) = dataset(indexSet(i))}dataset.trimEnd(dataset.length - indexSet.length)println(dataset)// inefficient oneprintln("removeAllButFirstNegativeInefficient")val dataset = ArrayBuffer(1, 2, -3, 4, -5, 6, 7, -9 )println("input array:" + dataset)var first = truevar i = 0while (i < dataset.length){  if ( dataset(i) < 0 ){    if ( first ){      first = false; i += 1    }else{      dataset.remove(i);    }  }else {    i += 1  }}println("result:\t" + dataset)``````scalaval a5 = Array(1, 7, 2, 9)println(a5.sum)                // 19println(a5.mkString(" | "))    // 1 | 7 | 2 | 9println(a5)                    // some value like [I@16f7412```#### array sorting```scalavar a1 = ArrayBuffer(1, 3,  1, 2, 8, 5)val aRes = a1.sortBy(x => -x)   //  a1.sortBy(-_)val aRes2 = a1.sortWith(_ > _)println(aRes)        // ArrayBuffer(8, 5, 3, 2, 1, 1)println(aRes2)       // ArrayBuffer(8, 5, 3, 2, 1, 1)````You can sort an array, but not an array buffer, in place`:  ```scalaval a = Array(1, 7, 2, 9)scala.util.Sorting.quickSort(a)// a is now Array(1, 2, 7, 9)```For the min, max, and quickSort methods, the element type must have a comparison operation. This is the case for numbersstrings, and other types with the __Ordered trait__.#### multidimensional arraysLike in Java, multidimensional arrays are implemented as arrays of arrays. For example, a two-Dimensional array of Double values has the type Array[Array[Double]]. To construct such an array, use the ofDim method:```scalaval matrix = Array.ofDim[Int](3,4) // Three rows, four columnsval raggerArray = new Array[Array[Int]](5)for (i <- 0 until raggerArray.length ){  raggerArray(i) = new Array[Int](i+2)      }```To access an element, use two pairs of parentheses:  `matrix(row)(column) = 42`####  Interoperating with JavaSince Scala arrays are implemented as Java arrays, you can pass them back and forth between Java and Scala.  If you call a Java method that receives or returns a java.util.List, you could, of course, use a Java ArrayList in your Scala code— but that is unattractive. Instead, import the implicit conversion methods in scala.collection.JavaConversions. Then you can use Scala buffers in your code, and they automatically get wrapped into Java lists when calling a Java method.```scalaimport scala.collection.JavaConversions.bufferAsJavaList import scala.collection.mutable.ArrayBufferval command = ArrayBuffer("ls", "-al", "/home/cay")val pb = new ProcessBuilder(command) // Scala to Java                                     // java.lang.ProcessBuilder, plain java class, one of constructor takes java.util.List as parameter```The Scala buffer is wrapped into an object of a Java class that implements the java.util.List interface.Conversely, when a Java method returns a java.util.List, you can have it automatically converted into a Buffer:```scalaimport scala.collection.JavaConversions.asScalaBuffer import scala.collection.mutable.Bufferval cmd : Buffer[String] = pb.command() // Java to Scala// You can't use ArrayBuffer—the wrapped object is only guaranteed to be a Buffer``````scalaval command = ArrayBuffer("ls", "-al", "/home/cay")val pb = new ProcessBuilder(command)val cmd: Buffer[String] = pb.command()println(cmd)      // ArrayBuffer(ls, -al, /home/cay)```Maps and Tuples---* Scala has a pleasant syntax for creating, querying, and traversing maps.   * You need to choose between mutable and immutable maps.  * `By default, you get a hash map, but you can also get a tree map`.* You can easily convert between Scala and Java maps. * **Tuples** are useful for aggregating values.Scala has a general notion of **tuples**—aggregates of n objects, not necessarily of the same type. A **pair** is simply a tuple with n = 2.You can construct a map as  ```scalaval scores = Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8)```This constructs an immutable Map[String, Int] whose contents can’t be changed. If you want a mutable map, use  ```scalaval scores = scala.collection.mutable.Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8)```If you want to start out with a blank map, you have to supply type parameters:  ```scalaval scores = new scala.collection.mutable.HashMap[String, Int]```#### pairIn Scala, `a map is a collection of pairs`. A **pair** is simply a grouping of two values, not necessarily of the same type, such as ("Alice", 10).The `-> operator` makes a pair.  ```scala "Alice" -> 10  res1: (String, Int) = (Alice,10)  //PS: it is not a Range```You could have equally well defined the map as  ```scalaval scores = Map(("Alice", 10), ("Bob", 3), ("Cindy", 8))``````scalaval scores_im = Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8)val scores1 = new scala.collection.mutable.HashMap[String, Int]val scores2 = scala.collection.mutable.Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8)val scores3 = Map(("Alice", 10), ("Bob", 3), ("Cindy", 8))````In Scala, the analogy between functions and maps is particularly close because you use the () notation to look up key values.`  ```scalaval bobsScore = scores("Bob") // Like scores.get("Bob") in Java````If the map doesn’t contain a value for the requested key, an exception is thrown.````scalaval bobsScore = if (scores.contains("Bob")) scores("Bob") else 0```Since this call combination is so common, there is a shortcut:  ```scalaval bobsScore = scores.getOrElse("Bob", 0)```If the map contains the key "Bob", return the value; otherwise, return 0.  Finally, the call map.get(key) returns an **Option** object that is either Some(value for key) or None. __operate with mutable map__   ```scalaval scores2 = scala.collection.mutable.Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8)scores2("Bob") = 30         // Updates the existing value for the key "Bob"scores2("NewGuy") = -1      // Adds a new key/value pair to scores2, "NewGuy" -> -1println(scores2)            // Map(Bob -> 30, NewGuy -> -1, Alice -> 10, Cindy -> 8)scores2 += ( "Bob" -> 15, "NewGuy2" -> 15 )println(scores)            // Map(Bob -> 15, NewGuy -> -1, Alice -> 10, NewGuy2 -> 15, Cindy -> 8)scores -= "NewGuy2"println(scores2)            // Map(Bob -> 15, NewGuy -> -1, Alice -> 10, Cindy -> 8)```__operate with immutable map__   You can’t update an immutable map, but you can do something that’s just as useful—obtain a new map that has the desired update:  ```scalaval newScores = scores + ("Bob" -> 10, "Fred" -> 7) // New map with update```The newScores map contains the same associations as scores, except that "Bob" has been updated and "Fred" added.Instead of saving the result as a new value, you can update a var:  ```scalavar scores = ...scores = scores + ("Bob" -> 10, "Fred" -> 7)```Similarly, to remove a key from an immutable map, `use the - operator to obtain a new map without the key`:  ```scalascores = scores - "Alice"```You might think that it is inefficient to keep constructing new maps, but that is not the case. `The old and new maps share most of their structure.` (This is possible because they are immutable.)The following amazingly simple loop iterates over all key/value pairs of a map:  ```scalafor ((k, v) <- map ) process k and v```For example:  ```scalaval scores = Map(Bob -> 15, NewGuy -> -1, Alice -> 10, Cindy -> 8)for ( (k,v) <- scores ){  println(k + "->" + v)}println(scores.keySet)    // Set(Bob, NewGuy, Alice, Cindy)for( v <- scores.values ) {  println(v)}// To get an immutable tree map instead of a hash mapval scoresSorted = scala.collection.immutable.SortedMap("Alice" -> 10, "Fred" -> 7, "Bob" -> 3, "Cindy" -> 8)val inversedScores = for( (k, v) <- scores ) yield (v,k)println(inversedScores)   // Map(8 -> Cindy, -1 -> NewGuy, 10 -> Alice, 15 -> Bob)````When working with a map, you need to choose an implementation—a hash table or a balanced tree. By default, Scala gives you a hash table.` You might want a tree map if you don’t have a good hash function for the keys, or if you need to visit the keys in sorted order.`Unfortunately, there is (as of Scala 2.9) no mutable tree map. Your best bet is to adapt a Java TreeMap,`If you want to visit the keys in insertion order, use a LinkedHashMap.  ```scalaval months = scala.collection.mutable.LinkedHashMap("January" -> 1, "February" -> 2, "March" -> 3, "April" -> 4,"May" -> 5)```#### Interoperating with Java for mapIf you get a Java map from calling a Java method, you may want to convert it to a Scala map so that you can use the pleasant Scala map API. This is also useful if you want to work with a mutable tree map, which Scala doesn’t Provide.```scalaimport scala.collection.JavaConversions.mapAsScalaMapimport scala.collection.JavaConversions.propertiesAsScalaMapimport scala.collection.JavaConversions.mapAsJavaMapimport java.awt.font.TextAttribute._val scores1: scala.collection.mutable.Map[String, Int] = new java.util.TreeMap[String, Int];val scores2: scala.collection.mutable.Map[String, String] = System.getPropertiesval attr = Map(FAMILY -> "Serif", SIZE -> 12)val font = new java.awt.Font(attr)```#### Tuples```scalaval tup1 = (1, 3.14, "Fred")println(tup1)println(tup1._2)println(tup1 _3)var (first, _, third) = tup1 println(first)println("New York".partition { x => x.isUpper })val res = "New York".partition(_.isUpper)println(res)    // Yields the pair ("NY", "ew ork")```#### Tuples to MapThe toMap method turns a collection of pairs into a map.  If you have a collection of keys and a parallel collection of values, then zip them up and turn them into a map like this:  ```scalakeys.zip(values).toMap``````scalaval symbols = Array("<", "-", ">") val counts = Array(2, 10, 3)val pairs = symbols.zip(counts)// yields an array of pairs Array(("<", 2), ("-", 10), (">", 3))for ( pair  <- pairs ){  println(pair)}println(pairs.toMap)    // Map(< -> 2, - -> 10, > -> 3)```Classes---* `Fields in classes automatically come with getters and setters`.  * You can replace a field with a custom getter/setter without changing the client of a class—that is the “uniform access principle.”  * Use the @BeanProperty annotation to generate the JavaBeans getXxx/setXxx methods.  * Every class has a **primary constructor** that is “interwoven” with the class definition. Its parameters turn into the fields of the class. The primary constructor executes all statements in the body of the class.  * Auxiliary constructors are optional. They are called this.`Methods are public by default``In Scala, a class is not declared as public. A Scala source file can contain multiple classes, and all of them have public visibility.````scalaclass Counter {  private var value = 0 // You must initialize the field  def increment() { value += 1 } // Methods are public by default  def current() = value  def enforcedCurrent = value}val myCounter = new Counter // Or new Counter()myCounter.increment()println(myCounter.current)  // or myCounter.current()println(myCounter.enforcedCurrent)  // can't use myCounter.enforcedCurrent()```It is considered good style to use () for a mutator method (a method that changes the object state), and to drop the () for an accessor method (a method that does not change the object state).Scala provides getter and setter methods for every field. Here, we define a public field:  ```scalaclass Person {     var age=0}```Scala generates a class for the JVM with a **private** age field and getter and setter methods. These methods are **public** becausewe did not declare age as private. (`For a private field, the getter and setter methods are private.`) In Scala, the getter and setter methods are called `age` and `age_=`.   For example,  ```scalaprintln(fred.age) // Calls the method fred.age() fred.age = 21 // Calls fred.age_=(21)```To see these methods with your own eyes, compile the Person class and then look at the bytecode with **javap**:  ```shell$ scalac Person.scala$ javap -private Person``````scalaCompiled from "Person.scala"public class Person extends java.lang.Object implements scala.ScalaObject{  private int age;  public int age();  public void age_$eq(int);  public Person();}```The = symbol is translated to $eq because the JVM does not allow an = in a method name.You can create a new property  ```scalaclass Person {  private var privateAge = 0 // Make private and rename  def age = privateAge  def age_=(newValue: Int) {    if (newValue > privateAge) privateAge = newValue; // Can't get younger  }}val fred = new Personfred.age = 30println(fred.age) // 30```Sometimes you want a read-only property with a getter but no setter. If the value of the property never changes after the object has been constructed, use a val field:```scalaclass Message {  val timeStamp = new java.util.Date  ...}```Scala makes `a private final field` and a getter method, but no setter.To summarize, you have four choices for implementing properties:1. var foo: Scala synthesizes a getter and a setter. 2. val foo: Scala synthesizes a getter.3. You define methods foo and foo_=.4. You define a method foo.In Scala, you cannot have a write-only property (that is, a property with a setter and no getter).  It may sound scary that Scala generates getter and setter methods for every field. But you have some control over this process.  1. If the field is private, the getter and setter are private.  2. If the field is a val, only a getter is generated.  3. If you don’t want any getter or setter, declare the field as **private[this]**#### Object-Private FieldsIn Scala (as well as in Java or C++), a method can access the private fields of all objects of its class.   ```scalaclass Counter {  private var value = 0  def increment() { value += 1 }  def isLess(other : Counter) = value < other.value  // Can access private field of other object}```Scala allows an even more severe access restriction, with the **private[this]** qualifier:   ```scalaclass Counter {  private[this] var value = 0 // Accessing someObject.value is not allowed}```Now, the methods of the Counter class can only access the value field of the current object, not of other objects of type Counter.With a class-private field, Scala generates private getter and setter methods. However, `for an object-private field, no getters and setters are generated at all.`Scala allows you to grant access rights to specific classes. The **private[ClassName]** qualifier states that only methods of the given class can access the given field. Here, the ClassName must be the name of the class being defined or an enclosing class.When you annotate a Scala field with `@BeanProperty`, then such methods are automatically generated. For example,  ```scalaimport scala.reflect.BeanPropertyclass Person {  @BeanProperty var name: String = _}```generates four methods:  1. name: String2. name_=(newValue: String): Unit3. getName(): String4. setName(newValue: String): UnitIf you define a field as a primary constructor parameter and you want JavaBeans getters and setters, annotate the constructor parameter like this:```scalaclass Person(@BeanProperty var name: String)```A Scala class has one constructor that is more important than all the others, called the primary constructor. In addition, a class may have any number of auxiliary constructors.#### auxiliary constructorAuxiliary constructors are very similar to constructors in Java or C++, with just two differences.  1. The auxiliary constructors are called `this`. (In Java or C++, constructors have the same name as the class—which is not so convenient if you rename the class.)2. Each auxiliary constructor must start with a call to a previously defined auxiliary constructor or the primary constructor.  ```scalaclass Person {  var name = ""  var age = 0  def this( name: String ){ // An auxiliary constructor    this()        // Calls primary constructor    this.name = name  }  def this( name: String, age : Int ){ // An auxiliary constructor    this(name)    // Calls previous auxiliary constructor    this.age = age  }}```#### primary constructorIn Scala, every class has a primary constructor. The primary constructor is not defined with a this method. Instead, it is interwoven with the class definition.If there are no parameters after the class name, then the class has a primary constructor with no parameters. That constructor simply executes all statements in the body of the class.1. The parameters of the primary constructor are placed immediately after the class name.2. `The primary constructor executes all statements in the class definition`  ```scala// class with primary constructorclass NewPerson(val name: String = "", private var age: Int = 0 ) {  println("initiating the object")}```Construction parameters can also be regular method parameters, `without val or var`. How these parameters are processed depends on their usage inside the class.  1. If a parameter without val or var is used inside at least one method, it becomes a field. For example,  ```scalaclass Person(name: String, age: Int) {  def description = name + " is " + age + " years old"}```declares and initializes immutable fields name and age that are object-private.   Such a field is the equivalent of a private[this] val field   2. Otherwise, the parameter is not saved as a field. It’s just a regular parameter that can be accessed in the code of the primary constructor. (Strictly speaking, this is an implementation-specific optimization.)When you think of the primary constructor’s parameters as class parameters, parameters without val or var become easier to understand. The scope of such a parameter is the entire class. `Therefore, you can use the parameter in methods. If you do, it is the compiler’s job to save it in a field.`Martin Odersky suggests to think about it this way: In Scala, classes takeparameters, just like methods do.You can often eliminate auxiliary constructors by using default arguments in the primary constructor. For example:```scalaclass Person(val name: String = "", val age: Int = 0)```To make the primary constructor private, place the keyword private like this:  ```scalaclass Person private(val id: Int) { ... }```A class user must then use an auxiliary constructor to construct a Person object.`In scala, inner class belongs to instance of outer class`, this is different from Java, where an inner class belongs to the outer class.(only for static inner class??)The Scala approach is more regular. For example, to make a new inner object, you simply use new with the type name:  ```scalanew chatter.Member. ```In Java, you need to use a special syntax, chatter.new Member().Tow ways to resolve,  1. move inner class to outer class's companion object  2. to use a type projection OuterClass#InnerClass, which means “a InnerClass of any OuterClass.”In a nested class, you can access the this reference of the enclosing class as **EnclosingClass.this**, like in Java. Objects---In this short chapter, you will learn when to use the object construct in Scala. `Use it when you need a class with a single instance, or when you want to find a home for miscellaneous values or functions.`    The key points of this chapter are:    * Use objects for singletons and utility methods.  * A class can have a companion object with the same name.  * Objects can extend classes or traits.  * The apply method of an object is usually used for constructing new instances of the companion class.   * To avoid the main method, use an object that extends the **App** trait.  * You can implement enumerations by extending the Enumeration object.  `Scala has no static methods or fields. Instead, you use the object construct.`An object defines a single instance of a class with the features that you want.```scalaobject Accounts {  private var lastNumber = 0  def newUniqueNumber() = { lastNumber += 1; lastNumber }}```The constructor of an object is executed when the object is first used.In our example, the Accounts constructor is executed with the first call to Accounts.newUniqueNumber().`An object can have essentially all the features of a class`—it can even extend other classes or traits (see Section 6.3, “Objects Extending a Class or Trait,” on page 67). `There is just one exception: You cannot provide constructor parameters`.#### Companion ObjectsIn Java or C++, you often have a class with both instance methods and static methods. In Scala, you achieve this by having a class and a “companion” object of the same name. ```scalaclass Account {  var id = Account.newUniqueNumber()  private var balance = 0.0  def deposit(amount : Double) {    balance += amount  }}// companion objectobject Account{  private var lastNumber = 0  def newUniqueNumber () = { lastNumber += 1; lastNumber }}```The class and its companion object can access each other’s private features.   They must be located in the same source file.  The companion object of a class is accessible, but it is not in scope. For example, the Account class has to call Account.newUniqueNumber() and not just newUniqueNumber() to invoke the method of the companion object.__Objects Extending a Class or Trait__  An object can extend a class and/or one or more traits. The result is an object of a class that extends the given class and/or traits, and in addition has all of the features specified in the object definition.#### The apply Method 1It is common to have objects with an apply method. The apply method is called for expressions of the form Object(arg1, ..., argN)  Typically, such an apply method returns an object of the companion class.Why doesn’t one just use a constructor? Not having the new keyword is handy for nested expressions, such as  ```scala  Array(Array(1, 7), Array(2, 9))```It is easy to confuse Array(100) and new Array(100). The first expression calls apply(100), yielding an Array[Int] with a single element, the integer 100. The second expression invokes the constructor this(100). The result is an `Array[Nothing]` with 100 null elements.#### Application Objects`Each Scala program must start with an object’s main method of type (Array[String]) => Unit`:  ```scalaobject Hello {  def main(args: Array[String]) {    println("hello world")  }}```Instead of providing a main method for your application, you can extend the App trait and place the program code into the constructor body:  ```scalaobject Hello extends App {    if (args.length > 0){    println("hello " + args(0))  }else{    println("hello world")  }}```If you need the command-line arguments, you can get them from the **args** propertyIf you invoke the application with the `scala.time` option set, then the elapsed time is displayed when the program exits.  ```shell$ scalac Hello.scala$ scala -Dscala.time Hello FredHello, Fred[total 4ms]```All this involves a bit of magic. The App trait extends another trait, **DelayedInit**, that gets special handling from the compiler. All initialization code of a class with that trait is moved into `a delayedInit method`. The main of the App trait method captures the command-line arguments, calls the delayedInit method, and optionally prints the elapsed time.Older versions of Scala had an `Application trait` for the same purpose. That trait carried out the program’s action in the `static initializer`, which is not optimized by the just-in-time compiler. Use the App trait instead.#### EnumerationsUnlike Java or C++, `Scala does not have enumerated types`. However, the standard library provides an **Enumeration** helper class that you can use to produce enumerations.  `Define an object that extends the Enumeration class` and initialize each value in your enumeration with a call to the `Value method`.  ```scalaobject TrafficLightColor extends Enumeration{  val Red, Green, Blue = Value}```Here we define three fields, Red, Green, and Blue, and` initialize each of them with a call to Value`. This is a shortcut for  ```scalaval Red = Valueval Green = Valueval Blue = Value```Each call to the Value method returns a new instance of an inner class, also called Value.  Alternatively, you can pass IDs, names, or both to the Value method:  ```scalaval Red = Value(0, "Stop")val Yellow = Value(10) // Name "Yellow"val Green = Value("Go") // ID 11```If not specified, the ID is one more than the previously assigned one, starting with zero. The default name is the field name. You can now refer to the enumeration values as TrafficLightColor.Red, TrafficLightColor.Blue, and so on. If that gets too tedious, use a statement  ```scalaimport TrafficLightColor._```if you import TrafficLightColor._, you can use expression either Red or TrafficLightColor.Red```scalaimport TrafficLightColor._println(Red)  // "Red"println(TrafficLightColor.Red)  //"Red"```Remember that the type of the enumeration is TrafficLightColor.Value and not TrafficLightColor—that’s the type of the object holding the values. Some people recommend that you add a `type alias`  ```scalaobject TrafficLightColor extends Enumeration {  type TrafficLightColor = Value  val Red, Yellow, Green = Value}```Now the type of the enumeration is TrafficLightColor.TrafficLightColor, which is only an improvement if you use an import statement.  For example,```scalaimport TrafficLightColor._def doWhat(color: TrafficLightColor) = {  if (color == Red) "stop"  else if (color == Yellow) "hurry up"  else "go"}```However, without type alias, it would be like below, that's the only difference   ```scalaimport TrafficLightColor._def doWhat(color: TrafficLightColor.Value) = {  if (color == Red) "stop"  else if (color == Yellow) "hurry up"  else "go"}```The ID of an enumeration value is returned by the id method, and its name by the toString method.  The call TrafficLightColor.values yields a set of all values:  ```scalafor (c <- TrafficLightColor.values) println(c.id + ": " + c)```Finally, you can look up an enumeration value by its ID or name. Both of the following yield the object TrafficLightColor.Red:  ```scalaTrafficLightColor(0) // Calls Enumeration.applyTrafficLightColor.withName("Red")```Packages and Imports---Both packages and imports are more regular than in Java; they are also a bit more `flexible`.The key points of this chapter are:  * `Packages nest just like inner classes`* Package paths are not absolute.  * A chain x.y.z in a package clause leaves the intermediate packages x and x.y invisible.  * Package statements without braces at the top of the file extend to the entire file.  * `A package object can hold functions and variables`. * `Import statements can import packages, classes, and objects`.  * `Import statements can be anywhere`.  * `Import statements can rename and hide members`.* java.lang, scala, and Predef are always imported.  To add items to a package, you can include them in package statements, such as:  ```scalapackage com {   package horstmann {    package impatient {       class Employee ...    }   }}```Then the class name Employee can be accessed anywhere as com.horstmann.impatient.Employee.Unlike the definition of an object or a class, `a package can be defined in multiple files.``There is no enforced relationship between the directory of the source file and the package.`  Conversely, you can contribute to more than one package in a single file.#### Scope RulesScala packages nest just like all other scopes. You can access names from the enclosing scope.`In Java, this problem can’t occur because package names are always absolute, starting at the root of the package hierarchy. But in Scala, package names are relative, just like inner class names`. With inner classes, one doesn’t usually run into problems because all the code is in one file, under control of whoever is in charge of that file. But packages are open-ended. Anyone can contribute to a package at any time.One solution is to use `absolute package names`, starting with `_root_`, for example: ```scalaval subordinates = new _root_.scala.collection.mutable.ArrayBuffer[Employee]  ```Another approach is to use **“chained” package clauses**Most programmers use complete paths for package names, without the `_root_` prefix. This is safe as long as everyone avoids names scala, java, com, org, and so on, for nested packages.#### Chained Package ClausesA package clause can contain a “chain,” or path segment```scalapackage com.horstmann.impatient {  // Members of com and com.horstmann are not visible here   package people {    class Person    //...   }}```#### Top-of-File NotationInstead of the nested notation that we have used up to now, you can have package clauses at the top of the file, without braces.```scalapackage com.horstmann.impatient  package peopleclass Person //...```This is equivalent to```scalapackage com.horstmann.impatient {   package people {    class Person    // ...    // Until the end of the file  } }```#### Package ObjectsA package can contain classes, objects, and traits, but not the definitions of functions or variables. That’s an unfortunate limitation of the Java virtual machine. It would make more sense `to add utility functions or constants to a package` than to some Utils object. `Package objects address this limitation.``Every package can have one package object.` `You define it in the parent package`, and it has the same name as the child package. For example,  ```scalapackage com.horstmann.impatientpackage object people {  val defaultName = "John Q. Public"}package people {   class Person {    var name = defaultName // A constant from the package   }  ... }```Note that the defaultName value didn’t need to be qualified because it was in the same package. Elsewhere, it is access as `com.horstmann.impatient.people.defaultName`.`Behind the scenes, the package object gets compiled into a JVM class with static methods and fields`, called `package.class` In our example, that would be a class com.horstmann.impatient.people.package with a static field defaultName. (In the JVM, you can use package as a class name.)It is a good idea to use the same naming scheme for source files. Put the package object into a file `com/horstmann/impatient/people/package.scala`. That way, anyone who wants to add functions or variables to a package can find the package object easily.In Java, a class member that isn’t declared as public, private, or protected is visible in the package containing the class. In Scala, you can achieve the same effect with qualifiers. The following method is visible in its own package, or even enclosing package:  ```scalapackage com.horstmann.impatient.peopleclass Person {  private[people] def description = "A person with name " + name   ...}```You can extend the visibility to an enclosing package:  ```scalaprivate[impatient] def description = "A person with name " + name```You can import all members of a package as  ```scalaimport java.awt._```This is the same as the * wildcard in Java. In Scala, `* is a valid character for an identifier`. You could define a package com.horstmann.*.people, but please don’t.`You can also import all members of a class or object.`   ```scalaimport java.awt.Color._val c1 = RED // Color.REDval c2 = decode("#ff0000") // Color.decode````This is like import static in Java`. Java programmers seem to live in fear of this variant, but in Scala it is commonly used.  Once you import a package, you can access its subpackages with shorter names. For example:  ```scalaimport java.awt._  def handler(evt: event.ActionEvent) { // java.awt.event.ActionEvent  ...}```The event package is a member of java.awt, and the import brings it into scope.In Scala, `an import statement can be anywhere`, not just at the top of a file. The scope of the import statement extends until the end of the enclosing block.This is a very useful feature, particularly with wildcard imports. It is always a bit worrisome to import lots of names from different sources. In fact, some Java programmers dislike wildcard imports so much that they never use them, but let their IDE generate long lists of imported classes.  By putting the imports where they are needed, you can greatly reduce the potential for conflicts.#### Renaming and Hiding MembersIf you want to import a few members from a package, use a selector like this:  ```scalaimport java.awt.{Color, Font}```The selector syntax lets you rename members:  ```scalaimport java.util.{HashMap => JavaHashMap}import scala.collection.mutable._```Now JavaHashMap is a java.util.HashMap and plain HashMap is a scala.collection. mutable.HashMap.  The selector `=> _` hides a member instead of renaming it. This is only useful if you import others:  ```scalaimport java.util.{HashMap => _, _}import scala.collection.mutable._```Now HashMap unambiguously refers to scala.collection.mutable.HashMap since java.util.HashMap is hidden.Every Scala program implicitly starts with  ```scalaimport java.lang._  import scala._  import Predef._  ```Next, the scala package is imported, but in a special way. Unlike all otherimports, `this one(the scala package) is allowed to override the preceding import`. For example, scala.StringBuilder overrides java.lang.StringBuilder instead of conflicting with it.Inheritance---* The extends and final keywords are as in Java.* You must use override when you override a method.* Only the primary constructor can call the primary superclass constructor.* `You can override fields`.You can also declare individual methods or `fields` final so that they cannot be overridden. Note that this is different from Java, where a final field is immutable, similar to val in Scala.In Scala, you must use the override modifier when you override a method that isn’t abstract.#### Type Checks and CastsTo test whether an object belongs to a given class, use the `isInstanceOf` method. If the test succeeds, you can use the `asInstanceOf` method to convert a reference to a subclass reference:  ```scalaif (p.isInstanceOf[Employee]) {  val s = p.asInstanceOf[Employee] // s has type Employee  ...}```The p.isInstanceOf[Employee] test succeeds if p refers to an object of class Employee or its subclass (such as Manager).  `If p is null, then p.isInstanceOf[Employee] returns false and p.asInstanceOf[Employee] returns null.`  `If p is not an Employee, then p.asInstanceOf[Employee] throws an exception`.   PS: subclass.isInstanceOf[parentClass]  returns true   If you want to test whether p refers to an Employee object, but not a subclass, use  ```scalaif (p.getClass == classOf[Employee])```The classOf method is defined in the scala.Predef object that is always imported.However, pattern matching is usually a better alternative to using type checks and casts.(PS: its implementation is like isInstanceOf) For example,  ```scalaval child = new Childchild match {  case p: Parent => println("enter parent branch"); p.doSomething    // Process p as an Parent  case c: Child => println("enter child branch"); c.doSomething  case _ => // child wasn't an Employee}// prints: "enter parent branch"```As in Java or C++, you can declare a field or method as protected. Such a member is accessible from any subclass, but not from other locations.  `Unlike in Java, a protected member is not visible throughout the package to which the class belongs.`  There is also a protected[this] variant that restricts access to the current object, similar to the private[this] variantThe auxiliary constructors of the subclass eventually call the primary constructor of the subclass. `Only the primary constructor can call a superclass constructor. `  As a consequence, an auxiliary constructor can never invoke a superclass constructor directly.  `In a Scala constructor, you can never call super(params)`, as you would in Java, to call the superclass constructor.This defines a subclass and a primary constructor that calls the superclass constructor  ```scalaclass Employee(name: String, age: Int, val salary : Double) extendsPerson(name, age)class Person( name: String, age: Int )````A Scala class can extend a Java class. Its primary constructor must invoke one of the constructors of the Java superclass`. For example,  ```scalaclass Square(x: Int, y: Int, width: Int) extends java.awt.Rectangle(x, y, width, width)```#### Overriding Fields1. A def can only override another def.2. A val can only override another val or a parameterless def.3. A var can only override an abstract var```scalaclass Person(val name: String) {  override def toString = getClass.getName + "[name=" + name + "]"}class SecretAgent(codename: String) extends Person(codename) {  override val name = "secret" // Don't want to reveal name . . .  override val toString = "secret" // . . . or class name}```A more common case is to override an abstract def with a val, like this:  ```scalaabstract class Person { // See Section 8.8 for abstract classes  def id: Int // Each person has an ID that is computed in some way  ...}class Student(override val id: Int) extends Person  // A student ID is simply provided in the constructor```#### Anonymous SubclassesAs in Java, you make an instance of an anonymous subclass if you include a block with definitions or overrides, such as  ```scalaval alien = new Person("Fred") {  def greeting = "Greetings, Earthling! My name is Fred."}```Technically, this creates an object of a structural type—see Chapter 18 for details. The type is denoted as Person{def greeting:String}. You can use this type as a parameter type:  ```scaladef meet(p: Person{def greeting: String}) {  println(p.name + " says: " + p.greeting)}```#### Abstract FieldsIn addition to abstract methods, a class can also have abstract fields. An abstract field is simply a field without an initial value. For example,  ```scalaabstract class Person {  val id: Int  // No initializer—this is an abstract field with an abstract getter method  var name: String  // Another abstract field, with abstract getter and setter methods}```This class defines abstract getter methods for the id and name fields, and an abstract setter for the name field. `The generated Java class has no fields`.Concrete subclasses must provide concrete fields, for example:  ```scalaclass Employee(val id: Int) extends Person { // Subclass has concrete id propertyvar name = "" // and concrete name property}```You can always customize an abstract field by using an anonymous type:  ```scalaval fred = new Person {  val id = 1729  var name = "Fred"}````In Java, you have a similar issue when you call a method in a superclass constructor. The method might be overridden in a subclass, and it might not do what you want it to do.`You can debug construction order problems with the -Xcheckinit compiler flag. This flag generates code that throws an exception (instead of yielding the default value) when an uninitialized field is accessed.The **“early definition” syntax** lets you initialize val fields of a subclass before the superclass is executed. The syntax is so ugly that only a mother could love it. You place the val fields in a block after the extends keyword, like this:  ```scalaclass Bug extends {  override val range = 2} with Creatureclass Creature {  val range: Int = 10  val env: Array[Int] = new Array[Int](range)}class Ant extends Creature {  override val range = 2}```#### The Scala Inheritance Hierarchy![scala_inheritance_hierarchy_img_1]  Figure 8–1 shows the inheritance hierarchy of Scala classes. The classes that correspond to the primitive types in Java, as well as the type Unit, extend AnyVal.  All other classes are subclasses of the AnyRef class, which is a synonym for the Object class from the Java or .NET virtual machine.  Both AnyVal and AnyRef extend the Any class, the root of the hierarchy.  The Any class defines methods isInstanceOf, asInstanceOf, and the methods for equality and hash codes that we will look at in Section 8.12, “Object Equality,” on page 95.  AnyVal does not add any methods. It is just a marker for value types.  The AnyRef class adds the monitor methods wait and notify/notifyAll from the Object class. It also provides a synchronized method with a function parameter. That method is the equivalent of a synchronized block in Java. For example,  ```scalaaccount.synchronized { account.balance += amount }```All Scala classes implement the marker interface ScalaObject, which has no methods.  At the other end of the hierarchy are the Nothing and Null types.  Null is the type whose sole instance is the value null. You can assign null to any reference, but not to one of the value types.   The Nothing type has no instances. It is occasionally useful for generic constructs. For example, the empty list Nil has type List[Nothing], which is a subtype of List[T] for any T.  The Nothing type is not at all the same as void in Java or C++. In Scala, void is represented by the Unit type, the type with the sole value ().   `Note that Unit is not a supertype of any other type. However, the compiler still allows any value to be replaced by a ()`. Consider  ```scaladef printAny(x: Any) { println(x) }def printUnit(x: Unit) { println(x) }printAny("Hello") // Prints HelloprintUnit("Hello")// Replaces "Hello" with () and calls printUnit(()), which prints () at last```In Scala, the eq method of the AnyRef class checks whether two references refer to the same object. The equals method in AnyRef calls eq. When you implement a class, you should consider overriding the equals method to provide a natural notion of equality for your situation.  Be sure to define the equals method with parameter type Any.   ```scalafinal def equals(other: Any) = { ... }```Files and Regular Expressions---* Source.fromFile(...).getLines.toArray yields all lines of a file.* Source.fromFile(...).mkString yields the file contents as a string.* To convert a string into a number, use the toInt or toDouble method.* Use the Java PrintWriter to write text files.* "regex".r is a Regex object.* Use """whatever""" if your regular expression contains backslashes or quotes.* If a regex pattern has groups, you can extract their contents using the syntax for (regex(var1, ...,varn) <- string).To read all lines from a file, call the getLines method on a scala.io.Source object:  ```scalaimport scala.io.Sourceval source = Source.fromFile("myfile.txt", "UTF-8")val lineIterator = source.getLinesfor (l <- lineIterator) process lval lines1: Array = source.getLines.toArrayval lines: ArrayBuffer = source.getLines.toBufferval contents = source.mkString```Call close when you are done using the Source object.```scalafor (c <- source) process c     // processing charval tokens = source.mkString.split("\\s+")val source1 = Source.fromURL("http://horstmann.com", "UTF-8")val source2 = Source.fromString("Hello, World!")// Reads from the given string—useful for debuggingval source3 = Source.stdin// Reads from standard input```If you want to be able to peek at a character without consuming it (like istream::peek in C++ or a PushbackInputStreamReader in Java), call the buffered method on the source object. Then you can peek at the next input character with the head method without consuming it.```scalaval source = Source.fromFile("myfile.txt", "UTF-8")val iter = source.bufferedwhile (iter.hasNext) {  if (iter.head is nice)    process iter.next  else    ...} source.close()```Remember—you can always use the java.util.Scanner class to process a file that contains a mixture of text and numbers.Scala has no provision for reading binary files. You’ll need to use the Java library. Here is how you can read a file into a byte array:  ```scalaval file = new File(filename)val in = new FileInputStream(file)val bytes = new Array[Byte](file.length.toInt)in.read(bytes)in.close()```Scala has no built-in support for writing files. To write a text file, use a java.io.PrintWriter, for example:  ```scalaval out = new PrintWriter("numbers.txt")for (i <- 1 to 100) out.println(i)out.close()```The Serializable trait is defined in the scala package and does not require an import.```scala@SerialVersionUID(42L) class Person extends Serializable```The Scala collections are serializable, so you can have them as members of your serializable classes#### Process ControlScala was designed to scale from humble scripting tasks to massive programs. The scala.sys.process package provides utilities to interact with shell programs. You can write your shell scripts in Scala, with all the power that the Scala language puts at your disposal.  Here is a simple example:  ```scalaimport sys.process._"ls -al .." !```As a result, the ls -al .. command is executed, showing all files in the parent directory. The result is printed to standard output.The sys.process package contains an implicit conversion from strings to ProcessBuilder objects. The ! operator executes the ProcessBuilder object.The result of the ! operator is the exit code of the executed program: 0 if the program was successful, or a nonzero failure indicator otherwise.If you use !! instead of !, the output is returned as a string:  ```scalaval result = "ls -al .." !!```The process library uses the familiar shell operators | > >> < && ||, but it prefixes them with a # so that they all have the same precedence.You can pipe the output of one program into the input of another, using the #| operator:  ```scala"ls -al .." #| "grep sec" !``````scala// To redirect the output to a file, use the #> operator:"ls -al .." #> new File("output.txt") !// To append to a file, use #>> instead:"ls -al .." #>> new File("output.txt") !// To redirect input from a file, use #<:"grep sec" #< new File("output.txt") !// You can also redirect input from a URL:"grep Scala" #< new URL("http://horstmann.com/index.html") !```You can combine processes with p #&& q (execute q if p was successful) and p #|| q (execute q if p was unsuccessful). But frankly, Scala is better at control flow than the shell, so why not implement the control flow in Scala?If you need to run a process in a different directory, or with different environment variables, construct a ProcessBuilder with the apply method of the Process object. Supply the command, the starting directory, and a sequence of (name, value) pairs for environment settings:  ```scalaval p = Process(cmd, new File(dirName), ("LANG", "en_US"))```Then execute it with the ! operator:  ```scala"echo 42" #| p !```#### Regular ExpressionsWhen you process input, you often want to use regular expressions to analyze it. The scala.util.matching.Regex class makes this simple. To construct a Regex object, use the r method of the String class:  ```scalaval numPattern = "[0-9]+".r```If the regular expression contains backslashes or quotation marks, then it is a good idea to use the “raw” string syntax, """...""". For example:  ```scalaval wsnumwsPattern = """\s+[0-9]+\s+""".r// A bit easier to read than "\\s+[0-9]+\\s+".r```The findAllIn method returns an iterator through all matches. You can use it in a for loop:  ```scalafor (matchString <- numPattern.findAllIn("99 bottles, 98 bottles"))process matchString// or turn the iterator into an array:val matches = numPattern.findAllIn("99 bottles, 98 bottles").toArray// Array(99, 98)```Groups are useful to get subexpressions of regular expressions. Add parentheses around the subexpressions that you want to extract, for example:```scalaval numitemPattern = "([0-9]+) ([a-z]+)".r```To match the groups, use the regular expression object as an “extractor” (see Chapter 14), like this:  ```scalaval numitemPattern(num, item) = "99 bottles"// Sets num to "99", item to "bottles"```If you want to extract groups from multiple matches, use a for statement like this:  ```scalafor (numitemPattern(num, item) <- numitemPattern.findAllIn("99 bottles, 98 bottles"))process num and item```Traits---A class `implements one or more traits` in order to take advantage of the services that the traits provide. `A trait may require that implementing classes support certain features. However, unlike Java interfaces, Scala traits can supply default implementations for these features`, which makes them far more useful.  Key points of this chapter:  * `A class can implement any number of traits`.* Traits can require that implementing classes have certain fields, methods, or `superclasses`.* Unlike Java interfaces, a Scala trait can provide implementations of methods and fields.* `When you layer multiple traits, the order matters`—the trait whose methods execute first goes to the back.Scala, like Java, does not allow a class to inherit from multiple superclasses.   Some programming languages, in particular C++, allow multiple inheritance—`but at a surprisingly high cost`.Issues of multiple inheritance  1. Multiple inheritance works fine when you combine classes that have nothing in common. But if these classes have common methods or fields, thorny issues come up.  (In C++, you need to redefine the conflicting methods to clarify what you want.)2. diamond inheritance problem  ```scalaclass Person {  var name: String = _}class Student extends Person { ... }class Employee extends Person { ... }class TeachingAssistant extends Student, Employee { // Not actual Scala code}```We only want one name field inside a TeachingAssistant, not two. How do the fields get merged? How does the field get constructed? In C++, you use “virtual base classes,” a complex and brittle feature, to address this issue.You often want to implement some methods in terms of others, but you cannot do that in a Java interface. It is therefore common in Java to provide both an interface and an abstract base class, but that just kicks the can down the road. What if you need to extend two of those abstract base classes?Scala has traits instead of interfaces. A trait can have both abstract and concrete methods, and a class can implement multiple traits.If you need more than one trait, add the others using the with keyword:  ```scalaclass ConsoleLogger extends Logger with Cloneable with Serializable```All Java interfaces can be used as Scala traits.#### Objects with TraitsNow, nothing gets logged, which might seem pointless. But you can “mix in” a better logger when constructing an object.  ```scalatrait Logger {  def log(msg : String)}trait ConsoleLogger extends Logger {  def log (msg : String ){    println(msg)  }}trait FileLogger extends Logger {  def log (msg : String ){    println(msg)  }}abstract class SavingAccount extends Account with Logger {  def withdraw(amount: Double) {     if (amount > balance) {       log("Insufficient funds")      }else {       balance -= amount     }  }}```You can add, to a class or an object, multiple traits that invoke each other `starting with the last one`.  Instead, `super.log` calls the `next trait in the trait hierarchy`, which depends on the order in which the traits are added. Generally, `traits are processed starting with the last one`.  With traits, you cannot tell from the source code which method is invoked by super.someMethod. The exact method depends on the ordering of the traits in the object or class that uses them. This makes super far more flexible than in plain old inheritance.  If you need to control which trait’s method is invoked, you can specify it in brackets: `super[ConsoleLogger].log(...)`. The specified type must be an immediate supertype; you can’t access traits or classes that are further away in the inheritance hierarchy.  ```scalatrait Logger {  def log(msg : String)}trait TimestampLogger extends Logger{  abstract override def log(msg: String) {    super.log(new java.util.Date() + " " + msg)  }}trait ShortLogger extends Logger {  val maxLength = 15 // See Section 10.8 on fields in traits  abstract override def log(msg: String) {    super.log(      if (msg.length <= maxLength) msg else msg.substring(0, maxLength - 3) + "...")  }}    // print message like, "Sun Feb 06 17:45:45 ICT 2011 Insufficient...", ShortLogger is invoked at first    val acct1 = new SavingAccount with ConsoleLogger with TimestampLogger with ShortLogger    // print message like, "Sun Feb 06 1..."    val acct2 = new SavingAccount with ConsoleLogger with ShortLogger with TimestampLogger```#### Fields in TraitsA field in a trait can be concrete or abstract.   * If you supply an initial value, the field is concrete  In general, a class gets a field for each concrete field in one of its traits.These fields are not inherited; they are simply added to the subclass.  You can think of concrete trait fields as “assembly instructions” for the classes that use the trait. Any such fields become fields of the class.  * An uninitialized field in a trait is abstract and must be overridden in a concrete subclass.  ```scalatrait ShortLogger extends Logged {  val maxLength: Int // An abstract field  // ...}class SavingsAccount extends Account with ConsoleLogger with ShortLogger {  val maxLength = 20 // No override necessary  // ...}```This way of supplying values for trait parameters is particularly handy when you construct objects on the fly.   ```scalatrait ShortLogger extends Logged {  val maxLength: Int // An abstract field  // ...}class SavingsAccount extends Account with Logged { ... }val acct = new SavingsAccount with ConsoleLogger with ShortLogger {  val maxLength = 20}```The new statement constructs an instance of an anonymous class extending SavingsAccount (the superclass) with the Logged trait. #### Trait Construction OrderJust like classes, `traits can have constructors`, made up of field initializations and other statements in the trait’s body. Forexample,  ```scalatrait FileLogger extends Logger {  val out = new PrintWriter("app.log") // Part of the trait's constructor  out.println("# " + new Date().toString) // Also part of the constructor  def log(msg: String) { out.println(msg); out.flush() }}```Constructors execute in the following order:  * The superclass constructor is called first.* Trait constructors are executed after the superclass constructor but before the class constructor.* Traits are constructed left-to-right.* Within each trait, the parents get constructed first.* If multiple traits share a common parent, and that parent has already been constructed, it is not constructed again.* After all traits are constructed, the subclass is constructed.  For example, consider this class:  ```scalaclass SavingsAccount extends Account with FileLogger with ShortLogger  ```The constructors execute in the following order:  1. Account (the superclass).2. Logger (the parent of the first trait).3. FileLogger (the first trait).4. ShortLogger (the second trait). Note that its Logger parent has already been constructed.5. SavingsAccount (the class).#### linearization of the classThe constructor ordering is the reverse of the linearization of the class. The linearization is a technical specification of all supertypes of a type. It is defined by the rule:  If C extends C1 with C2 with . . . with Cn, then lin(C) = C » lin(Cn) » . . . » lin(C2) » lin(C1)Here, » means “concatenate and remove duplicates, with the right winning out.” For example,  ```scalaclass SavingsAccount extends Account with FileLogger with ShortLogger  ```lin(SavingsAccount)  = SavingsAccount » lin(ShortLogger) » lin(FileLogger) » lin(Account)  = SavingsAccount » (ShortLogger » Logger) » (FileLogger » Logger) » lin(Account)  = SavingsAccount » ShortLogger » FileLogger » Logger » Account.  (For simplicity, I omitted the types ScalaObject, AnyRef, and Any that are at the end of any linearization.)  The linearization gives the order in which super is resolved in a trait. For example, calling super in a ShortLogger invokes the FileLogger method, and calling super in a FileLogger invokes the Logger method.#### Initializing Trait Fields`Traits cannot have constructor parameters. Every trait has a single parameterless constructor`.  ```scalatrait Logger {  def log(msg : String)}trait FileLogger extends Logger {  val filename: String  val out = new PrintStream(filename)  def log(msg: String) { out.println(msg); out.flush() }}```1. early definition  ```scalaval acct = new { // Early definition block after new  val filename = "myapp.log"} with SavingsAccount with FileLogger// or in classclass SavingsAccount extends { // Early definition block after extends  val filename = "savings.log"} with Account with FileLogger {... // SavingsAccount implementation}```2. lazy value  ```scalatrait FileLogger extends Logger {  val filename: String  lazy val out = new PrintStream(filename)  def log(msg: String) { out.println(msg) } // No override needed}```However, lazy values are somewhat inefficient since they are checked for initialization before every use.`Less commonly, a trait can also extend a class. That class becomes a superclass of any class mixing in the trait`.   What if our class already extends another class? That’s OK, as long as it’s a subclass of the trait’s superclass.#### Self TypesWhen a trait starts out with  ```scalathis: Type =>```then it can only be mixed into a subclass of the given type.```scalatrait LoggedException extends Logged {  this: Exception =>  def log() { log(getMessage()) }}```Note that the trait does not extend the Exception class. Instead, it has a self type of Exception. That means, it can only be mixed into subclasses of Exception.There are a few situations where the self type notation is more flexible than traits with supertypes.   * Self types can handle circular dependencies between traits. This can happen if you have two traits that need each other.  * Self types `can also handle structural types—types that merely specify the methods that a class must have`, without naming the class. Here is the LoggedException using a structural type:  ```scalatrait LoggedException extends Logged {  this: { def getMessage() : String } =>  def log() { log(getMessage()) }}```The trait can be mixed into any class that has a getMessage method.Scala needs to translate traits into classes and interfaces of the JVM. You are not required to know how this is done, but you may find it helpful for understanding how traits work.  1. A trait that has only abstract methods is simply turned into a Java interface. For example,  ```scalatrait Logger {  def log(msg: String)}// turns intopublic interface Logger { // Generated Java interface  void log(String msg);}```2. If a trait has concrete methods  a companion class is created whose static methods hold the code of the trait’s methods. For example,```scalatrait ConsoleLogger extends Logger {  def log(msg: String) { println(msg) }}//turns intopublic interface ConsoleLogger extends Logger { // Generated Java interface  void log(String msg);}public class ConsoleLogger$class { // Generated Java companion class  public static void log(ConsoleLogger self, String msg) {    println(msg);  }}```These companion classes don’t have any fields. 3. Fields in traits yield abstract getters and setters in the interface. When a class implements the trait, the fields are added to that class. For example,  ```scalatrait ShortLogger extends Logger {  val maxLength = 15 // A concrete field  ...}//is translated topublic interface ShortLogger extends Logger{  public abstract int maxLength();  public abstract void weird_prefix$maxLength_$eq(int);  ...}```The weird setter is needed to initialize the field. This happens in an initialization method of the companion class:  ```scalapublic class ShortLogger$class {  public void $init$(ShortLogger self) {    self.weird_prefix$maxLength_$eq(15)  }}```When the trait is mixed into a class, the class gets a maxLength field with a getter and setter. The constructors of that class will call the initialization method.  In summary,     1. When a class implements the trait, the fields are added to that class    2. Fields in traits yield abstract getters and setters in the interface    3. If the field is initialized in trait, add an initialization method to the companion class, $init$(...), which will be called by implementing class's class constructor   4. If a trait extends a superclass, the companion class does not inherit that superclass. Instead, any class implementing the trait extends the superclass.Operators---**Operators** are often used to build **domain-specific languages**—minilanguages embedded inside Scala. **Implicit conversions** (type conversion functions that are applied automatically) are another tool facilitating the creation of domain-specific languages.The key points of this chapter are:  * Identifiers contain either alphanumeric or operator characters.* Unary and binary operators are method calls.* `Operator precedence depends on the first character, associativity on the last`.* The apply and update methods are called when evaluating expr(args).* Extractors extract tuples or sequences of values from an input .[Back](#indexes)   As in Java, Unicode characters are allowed.  In addition, you can use any sequence of operator characters:  * ASCII characters other than letters, digits, underscore, parentheses ()[]{}, or delimiters .,;'`". In other words, any of !#%&*+-/:<=>?@\^|~.* Unicode mathematical symbols or other symbols from the Unicode categories Sm and So.Finally, you can include just about any sequence of characters in backquotes. For example,  ```scalaval `val` = 42```That example is silly, but backquotes can sometimes be an “escape hatch.” For example, in Scala, yield is a reserved word, but you may need to access a Java method of the same name. Backquotes to the rescue:   ```scalaThread.`yield`().```Infix operators are binary operators—they have two parameters. An operator with one parameter is called a unary operator. If it follows the argument, it is a postfix operator. The expression   ```scalaa identifier```is the same as the method call `a.identifier()`. For example,   ```scala1 toString// is the same as1.toString()```The four operators +, -, !, ~ are allowed as prefix operators, appearing before their arguments. They are converted into calls to methods with the name unary_operator. For example,    ```scala-a//means the same as a.unary_-.````associativity` determines whether they are evaluated left-to-right or right-to-left. For example, in the expression 17 – 2 – 9, one computes (17 – 2) – 9. The – operator is left-associative.  In Scala, all operators are left-associative except for  * Operators that end in a colon (:)* Assignment operators  In particular, the :: operator for constructing lists is right-associative.Scala lets you extend the function call syntax  ```scalaf(arg1, arg2, ...)```to values other than functions. If f is not a function or method, then this expression is equivalent to the call  ```scalaf.apply(arg1, arg2, ...)```unless it occurs to the left of an assignment. The expression  ```scalaf(arg1, arg2, ...) = value```corresponds to the call  ```scalaf.update(arg1, arg2, ..., value)```An **extractor** is an object with an unapply method. You can think of the unapply method as being the opposite of the apply method of a companion object.An **unapply** method takes an object and extracts values from it—usually the values from which the object was constructed.  ```scalaclass Fraction(n: Int, d: Int) {  ...}object Fraction {  def apply(n: Int, d: Int) = new Fraction(n, d)  def unapply(input: Fraction) = if (input.den == 0) None else Some((input.num, input.den))}```In general, a pattern match can fail. Therefore, the unapply method returns an Option. It contains `a tuple with one value for each matched variable`. In our case, we return an Option[(Int, Int)].You can use unapply in following situations  * in a variable definition```scalavar Fraction(a, b) = Fraction(3, 4) * Fraction(2, 5)// a, b are initialized with the numerator and denominator of the result```* a pattern match  ```scalacase Fraction(a, b) => ... // a, b are bound to the numerator and denominatorFraction(10, 20) match {  case Fraction(a, b) => println(a + "/" + b)  case _ => println("no match") }// prints 10/20```In the preceding example, the apply and unapply methods are inverses of one another. However, that is not a requirement. You can use extractors to extract information from an object of any type.An extractor can just test its input without extracting any value. In that case, the unapply method should return a Boolean.   #### The unapplySeq MethodTo extract an arbitrary sequence of values, the method needs to be called unapplySeq. It returns an Option[Seq[A]], where A is the type of the extracted values.  PS: following example shows match is shortcut match, it matches the first pattern it meets, and the example shows how extractors test its input, or extract an sequence of values  ```scalaobject IsCompound {  def unapply(input : String) = input.contains("Wu")}object Name {  def unapplySeq( input: String ): Option[Seq[String]] =     if ( input.trim().equals("") ) None else Some(input.trim.split("\\s+"))}var author = "Nari Van De Wu"      // prints "ah Nari, Van, De, Wu"author = "Nari Wu"                 // prints "haha Nari, Wu"author = "Nari Jin"                // prints "wow Nari, Jin"author = "Nari De Wu"              // prints "oh Nari, De, Wu"author match {  case Name( first, last @ IsCompound() ) => printf("haha %s, %s\n", first, last)  case Name( first, last ) => printf("wow %s, %s\n", first, last)  case Name( first, middle, last ) => printf("oh %s, %s, %s\n", first, middle, last)  case Name( first, "De", last ) => printf("err %s, %s, %s\n", first, "De", last)  case Name( first, "Van", "De", last ) => printf("ah %s, %s, %s, %s\n", first, "Van", "De", last)}```Higher-Order Functions---This is very useful whenever you want to pass some detail action to an algorithm. In a functional language, you just wrap that detail into a function that you pass as a parameter.* Functions are “first-class citizens” in Scala, just like numbers.* You can create anonymous functions, usually to give them to other functions.* A function argument specifies behavior that should be executed later.* Many collection methods take function parameters, applying a function to the values of the collection.* There are syntax shortcuts that allow you to express function parameters in a way that is short and easy to read.* You can create functions that operate on blocks of code and look much like the built-in control statements.[Back](#indexes)   You can store a function in a variable:  ```scalaval fun = scala.math.ceil _```This code sets fun to the ceil function.  The _ behind the ceil function indicates that you really meant the function, and you didn’t just forget to supply the arguments.  `Technically, the _ turns the ceil method into a function.` In Scala, you cannot manipulate methods, only functions.  The type of fun is reported as  ```scala(Double) => Double```—that is, a function receiving and returning a Double.What can you do with a function? Two things:  1. Call it.  ```scalafun(num) // 4.0```As you can see, you use the normal function call syntax. The only difference is that fun is a variable containing a function, not a fixed function.  2. Pass it around, by storing it in a variable or giving it to a function as a parameter.  ```scalaArray(3.14, 1.42, 2.0).map(fun) // Array(4.0, 2.0, 2.0)```The map method accepts a function, applies it to all values in an array, and returns an array with the function values.#### Anonymous FunctionsIn Scala, you don’t have to give a name to each function, just like you don’t have to give a name to each number. Here is an anonymous function:  ```scala(x: Double) => 3 * x```This function multiplies its argument by 3.  Of course, you can store this function in a variable:  ```scalaval triple = (x: Double) => 3 * x```You can just pass it to another function:  ```scalaArray(3.14, 1.42, 2.0).map((x: Double) => 3 * x)// Array(9.42, 4.26, 6.0)```If you prefer, you can enclose the function argument in braces instead of parentheses, for example  ```scalaArray(3.14, 1.42, 2.0).map{ (x: Double) => 3 * x }```This is more common when a method is used in infix notation (without the dot).  ```scalaArray(3.14, 1.42, 2.0) map { (x: Double) => 3 * x }```#### Functions with Function Parameters```scala// its type is ((Double) => Double) => Doubledef valueAtOneQuarter(f: (Double) => Double) = f(0.25)valueAtOneQuarter(ceil _) // 1.0valueAtOneQuarter(sqrt _) // 0.5```Since valueAtOneQuarter is a function that receives a function, it is called a **higher-order function**A higher-order function can also produce a function. Here is a simple example:  ```scala// higher-order function that produces another function, whose type is// (Double) => ((Double) => Double)def mulBy( factor : Double ) = (x: Double) => factor * xmulBy(3)(1.0)    // 3.0```When you pass an anonymous function to another function or method, Scala helps you out by deducing types when possible.```scaladef valueAtOneQuarter(f: (Double) => Double) = f(0.25)valueAtOneQuarter((x:Double) => 3*x)```Since the valueAtOneQuarter method knows that you will pass in a (Double) => Double function, you can just write  ```scalavalueAtOneQuarter((x) => 3 * x)```As a special bonus, for a function that has just one parameter, you can omit the () around the parameter:  ```scalavalueAtOneQuarter(x => 3 * x)```It gets better. If a parameter occurs only once on the right-hand side of the =>, you can replace it with an underscore:  ```scalavalueAtOneQuarter(3 * _)```This is the ultimate in comfort, and it is also pretty easy to read: a function that multiplies something by 3.Keep in mind that these shortcuts only work when the parameter types are known.```scalaval fun = 3 * _ // Error: Can't infer typesval fun = 3 * (_: Double) // OKval fun: (Double) => Double = 3 * _ // OK because we specified the type for fun```A good way of becoming comfortable with higher-order functions is to practice with some common (and obviously useful) methods in the Scala collections library that take function parameters.   ```scalaprintln("*" * 3)       // ***(1 to 9).map(0.1 * _)  // Vector(0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9)(1 to 9).map("*" * _).foreach(println _)// *// **// ***// ****// *****// ******// *******// ********// *********(1 to 9).filter(_ % 2 == 0)  // Vector(2, 4, 6, 8)```Here, we also use **foreach**, which is like map except that its function doesn’t return a value. The foreach method simply applies the function to each argument.```scala// in scala.collection.Iterabledef reduceLeft[B >: A](op: (B, A) ⇒ B): B```Applies a binary operator to all elements of this traversable or iterator, going left to right.The reduceLeft method takes a binary function—that is, a function with two parameters—and applies it to all elements of a sequence, going from left to right. For example,```scala(1 to 9).reduceLeft(_ * _)   // 362880 = (((((((1 * 2) * 3) * 4) * 5 ) * 6) * 7) * 8) * 9```Note the compact form of the multiplication function: _ * _. Each underscore denotes a separate parameter.```scala// in scala.Arraydef sortWith(lt: (T, T) ⇒ Boolean): Array[T]"Mary had a little lamb".split(" ").sortWith(_.length < _.length) //a had Mary lamb little```#### ClosuresIn Scala, you can define a function inside any scope: in a package, in a class, or even inside another function or method. In the body of a function, you can access any variables from an enclosing scope. That may not sound so remarkable, but note that your function may be called when the variable is no longer in scope.```scaladef mulBy(factor : Double) = (x : Double) => factor * xval triple = mulBy(3)val half = mulBy(0.5)println(triple(14) + " " + half(14)) // Prints 42 7                                     // it didn't print either "42 42" or "7 7", means each of triple and half has its own version of factor parameter```Each of the returned functions has its own setting for factor.  Such a function is called a closure. A **closure** consists of `code together with the definitions of any nonlocal variables` that the code uses.These functions are actually implemented as objects of a class, with an instance variable factor and an apply method that contains the body of the function.Closures aren’t difficult or surprising if they are a natural part of the language. Many modern languages, such as JavaScript, Ruby, and Python, support closures. An outlier is Java, which, as of version 7, does not. A limited form of closures will be a part of Java 8.#### SAM ConversionsIn Scala, you pass a function as a parameter whenever you want to tell another function what to do. Java does not (currently) have functions, and a Java programmer has to work harder to achieve the same effect. Usually, one puts actions into a class implementing an interface, then gives an instance of that class to another method.  Many times, these interfaces have a `single abstract method`. They are called SAM types in Java.For example, suppose we want to increment a counter when a button is clicked.```scalavar counter = 0val button = new JButton("Increment")button.addActionListener(new ActionListener {  override def actionPerformed(event: ActionEvent) {    counter += 1  }})```That’s a lot of boilerplate! It would be nice if we could just pass a function to addActionListener, like this:  ```scalabutton.addActionListener((event: ActionEvent) => counter += 1)```To enable this syntax, you need to provide an implicit conversion. We will discuss these conversions in detail in Chapter 21, but you can easily add one without studying all the details. The following conversion turns a function into an ActionListener instance:  ```scalaimplicit def makeAction(action: (ActionEvent) => Unit) =new ActionListener {  override def actionPerformed(event: ActionEvent) { action(event) }}```Simply place this function with your user interface code, and you can pass any (ActionEvent) => Unit function where an ActionListener object is expected.#### CurryingCurrying (named after logician Haskell Brooks Curry) is the process of turning a function that takes two arguments into a function that takes one argument. That function returns a function that consumes the second argument.  Huh? Let’s look at an example. This function takes two arguments:  ```scaladef mul(x: Int, y: Int) = x * y```This function takes one argument, yielding a function that takes one argument:  ```scaladef mulOneAtATime(x: Int) = (y: Int) => x * y```To multiply two numbers, you call  ```scalamulOneAtATime(6)(7)```Strictly speaking, the result of mulOneAtATime(6) is the function (y: Int) => 6 * y. That function is applied to 7, yielding 42.  There is a shortcut for defining such curried functions in Scala:  ```scaladef mulOneAtATime(x: Int)(y: Int) = x * y```Sometimes, you want to use currying for a function parameter so that the type inferencer has more information.  Here is a typical example. The corresponds method can compare whether two sequences are the same under some comparison criterion. For example,  ```scalaval a = Array("Hello", "World")val b = Array("hello", "world")a.corresponds(b)(_.equalsIgnoreCase(_))   // true```Note that the function _.equalsIgnoreCase(_) is passed as a curried parameter, in a separate set of (...). When you look into the Scaladoc, you will see that corresponds is declared as   ```scaladef corresponds[B](that: Seq[B])(p: (A, B) => Boolean): Boolean```The that sequence and the predicate function p are separate curried parameters. The type inferencer can figure out what B is from the type of that, and then it can use that information when analyzing the function that is passed for p.   In our example, that is a String sequence. Therefore, the predicate is expected to have type (String, String) => Boolean. With that information, the compiler can accept _.equalsIgnoreCase(_) as a shortcut for (a: String, b: String) => a.equalsIgnoreCase(b).#### model a sequence of statements as a functionIn Scala, one can model a sequence of statements as a function with no parameters or return value. For example, here is a function that runs some code in a thread:  ```scaladef runInThread(block: () => Unit) {  new Thread {    override def run() { block() }  }.start()}```The code is given as a function of type () => Unit. However, when you call this function, you need to supply an unsightly `() =>`  ```scalarunInThread { () => println("Hi"); Thread.sleep(10000); println("Bye") }```To avoid the () => in the call, use the `call by name notation`: Omit the (), but not the =>, in the parameter declaration and in the call to the parameter function:  ```scaladef runInThread(block: => Unit) {  new Thread {    override def run() { block }  }.start()}```Then the call simply becomes  ```scalarunInThread { println("Hi"); Thread.sleep(10000); println("Bye") }```The technical term for such a function parameter is a **call-by-name** parameter. Unlike a regular (or **call-by-value**) parameter, the parameter expression is not evaluated when the function is called.#### control abstractionsScala programmers can build control abstractions: functions that look like they are language keywords. For example, we can implement a function that can be used exactly like a while statement. Or, we can innovate a bit and definean until statement that works like while, but with an inverted condition:  ```scaladef until(condition: => Boolean)(block: => Unit) {  if (!condition) {    block    until(condition)(block)  }}```Here is how you use until:  ```scalavar x = 10until ( x == 0 ){  x -= 1  println(x)}```The technical term for such a function parameter is a **call-by-name** parameter. Unlike a regular (or call-by-value) parameter, the parameter expression is not evaluated when the function is called. After all, we don’t want x == 0 to evaluate to false in the call to until. Instead, the expression becomes the body of a function with no arguments. That function is passed as a parameter.Look carefully at the until function definition. Note that it is curried: It first consumes the condition, then the block as a second parameter. Without currying, the call would look like this:  ```scalauntil(x == 0, { ... })```which wouldn’t be as pretty.In Scala, you don’t use a return statement to return function values. The return value of a function is simply the value of the function body.However, you can use return to return a value from an anonymous function to an enclosing named function. This is useful in control abstractions.(you need to specify return type of enclosing named function)`The control flow is achieved with a special exception that is thrown by the return expression in the anonymous function`, passed out of the anonymous function, and caught in the enclosing named function.If the exception is caught in a try block, before it is delivered to the named function, then the value will not be returned.Collections---* All collections extend the Iterable trait.* The three major categories of collections are sequences, sets, and maps.* `Scala has mutable and immutable versions of most collections`.* A Scala list is either empty, or it has a head and a tail which is again a list.* Sets are unordered collections.* Use a LinkedHashSet to retain the insertion order or a SortedSet to iterate in sorted order.* `+ adds an element to an unordered collection; +: and :+ prepend or append to a sequence; ++ concatenates two collections; - and -- remove elements`.* `The Iterable and Seq traits have dozens of useful methods for common operations. Check them out before writing tedious loops`.* Mapping, folding, and zipping are useful techniques for applying a function or operation to the elements of a collection.[Back To Indexes](#indexes)  ![scala_collection_hierarchy_img_1]An Iterable is any collection that can yield an Iterator with which you can access all elements in the collection:  ```scalaval coll = ... // some Iterableval iter = coll.iteratorwhile (iter.hasNext)  do something w ith iter.next()```This is the most basic way of traversing a collection. However, as you will see throughout this chapter, usually there are more convenient ways.`A Seq is an ordered sequence of values`, such as an array or list. An IndexedSeq allows fast random access through an integer index. For example, `an ArrayBuffer is indexed but a linked list is not`.A Set is an unordered collection of values. In a SortedSet, elements are always visited in sorted order.A Map is a set of (key, value) pairs. A SortedMap visits the entries as sorted by the keys. This hierarchy is similar to that in Java, with a couple of welcome improvements:  1. Maps are a part of the hierarchy and not a separate hierarchy.2. IndexedSeq is the supertype of arrays but not of lists, allowing you to tell the two apart.In Java, both ArrayList and LinkedList implement a common List interface, making it difficult to write efficient code when random access is preferred, for example when searching in a sorted sequence. This was a flawed design decision in the original Java collections framework. In a later version, a marker interface RandomAccess was added to deal with this problem.Each Scala collection trait or class has a companion object with an apply method for constructing an instance of the collection.  This is called the “uniform creation principle”.Scala supports both mutable and immutable collections. An immutable collection can never change, so you can safely share a reference to it, even in a multithreaded program.????Scala gives a preference to immutable collections.The companion objects in the scala.collection package produce immutable collections. For example,   ```scalascala.collection.Map("Hello" -> 42) // is an immutable map.```Moreover, the scala package and the Predef object, which are always imported, have type aliases List, Set, and Map that refer to the immutable traits. For example, `Predef.Map` is the same as `scala.collection.immutable.Map`.![scala_collection_hierarchy_immutable_img_1]  A Vector is the immutable equivalent of an ArrayBuffer: an indexed sequence with fast random access. Vectors are implemented as trees where each node has up to 32 children. For a vector with one million elements, one needs four layers of nodes. (Since 10^3 ≈ 2^10, 10^6 ≈ 32^4.) Accessing an element in such a list will take 4 hops, whereas in a linked list it would take an average of 500,000.A Range represents an integer sequence, such as 0,1,2,3,4,5,6,7,8,9 or 10,20,30. Of course a Range object doesn’t store all sequence values but only the start, end, and increment. You construct Range objects with the to and until methods__the most useful mutable sequences__:  We discussed **array buffers** in Chapter 3. **Stacks**, **queues**, and **priority queues** are standard data structures that are useful for implementing certain algorithms. If you are familiar with these structures, the Scala implementations won’t surprise you. The **linked list** classes, on the other hand, are a bit different from the linked lists that you may have encountered in Java, C++, or a data structures course.#### Scala ListsIn Scala, a list is either Nil (that is, empty) or an object with a head element and a tail that is again a list. For example, consider the list```scalaval digits = List(4, 2)```The value of digits.head is 4, and digits.tail is List(2). Moreover, digits.tail.head is 2 and digits.tail.tail is Nil.  The :: operator makes a new list from a given head and tail. For example,  ```scala9 :: List(4, 2)```is List(9, 4, 2). You can also write that list as  ```scala9 :: 4 :: 2 :: Nil```Note that :: is right-associative. With the :: operator, lists are constructed from the end.  ```scala9 :: (4 :: (2 :: Nil))``````scaladef sum(lst: List[Int]): Int = lst match {  case Nil => 0  case h :: t => h + sum(t) // h is lst.head, t is lst.tail}```Note the :: operator in the second pattern. It “destructures” the list into head and tail.The mutable **LinkedList** works like the immutable List, except that you can modify the **head** by assigning to the elem reference, and the **tail** by assigning to the next reference.```scala// For example, this loop changes all negative values to zeroval lst = scala.collection.mutable.LinkedList(1, -2, 7, -9)var cur = lstwhile (cur != Nil) {  if (cur.elem < 0) cur.elem = 0  cur = cur.next}// This loop removes every second element from the listcur = lstwhile (cur != Nil && cur.next != Nil) {  cur.next = cur.next.next  cur = cur.next}```You may wonder why sets don’t retain the element order. It turns out that you can find elements much faster if you allow sets to reorder their elements. Finding an element in a hash set is much faster than in an array or list.  A linked hash set remembers the order in which elements were inserted. It keeps a linked list for this purpose.  Sorted sets are implemented as red-black trees.A bit set is an implementation of a set of nonnegative integers as a sequence of bits. The ith bit is 1 if i is present in the set. This is an efficient implementation as long as the maximum element is not too large. Scala provides both mutable and immutable **BitSet** classes.The union, intersect, and diff methods carry out the usual set operations. If you prefer, you can write them as |, &, and &~. You can also write union as ++ and difference as --.Note that +:, like all operators ending in a colon, is right-associative, and that it is a method of the right operand.```scalavar numberVector = Vector(1, 2, 3)numberVector :+= 5 // += does not work since vectors don't have a + operator```As you can see, Scala provides many operators for adding and removing elements. Here is a summary:  1. Append (:+) or prepend (+:) to a sequence.2. Add (+) to an unordered collection.3. Remove with -.4. Use ++ and -- for bulk add and remove.5. For lists, :: and ::: are preferred.6. Mutations are += ++= -= --=.7. For sets, I prefer ++ & --.8. I stay away from ++: +=: ++=:.#### Mapping a Function* flatMap  If the function yields a collection instead of a single value, you may want to concatenate all results. In that case, use **flatMap** instead of map. For example, consider  ```scalaval names = List("Peter", "Paul", "Mary")def ulcase( s: String ) = Vector( s.toUpperCase(), s.toLowerCase() )println(names.map(ulcase))      // List(Vector(PETER, peter), Vector(PAUL, paul), Vector(MARY, mary))println(names.flatMap(ulcase))  // List(PETER, peter, PAUL, paul, MARY, mary)```If you use flatMap with a function that returns an Option, the resulting collection contains all values v for which the function returns Some(v).* collect  The **collect** method works with partial functions—functions that may not be defined for all inputs. It yields a collection of all function values of the arguments on which it is defined. For example,  ```scala"-3+4".collect { case '+' => 1 ; case '-' => -1 } // Vector(-1, 1)```* foreach  Finally, if you just want to apply a function for its side effect and don’t care about the function values, use foreach:  ```scalanames.foreach(println)```#### Reducing, Folding, and Scanning* reduce  The map method applies a unary function to all elements of a collection. The methods that we discuss in this section combine elements with a binary function. The call `c.reduceLeft(op)` applies op to successive elements, like this:  ![scala_collection_binary_operation_img_1]  * foldOften, it is useful to start the computation with an initial element other than the initial element of a collection. The call   ```scalacoll.foldLeft(init)(op)```computes    ![scala_collection_binary_operation_img_2]  You can also write the foldLeft operation with the /: operator, like this:  ```scala(0 /: List(1, 7, 2, 9))(_ - _)```The /: is supposed to remind you of the shape of the tree.Folding is sometimes attractive as a replacement for a loop. Suppose, for example, we want to count the frequencies of the letters in a string. One way is to visit each letter and update a mutable map.  ```scalaval freq = scala.collection.mutable.Map[Char, Int]()for (c <- "Mississippi") freq(c) = freq.getOrElse(c, 0) + 1// Now freq is Map('i' -> 4, 'M' -> 1, 's' -> 4, 'p' -> 2)```Here is another way of thinking about this process. At each step, combine the frequency map and the newly encountered letter, yielding a new frequency map.  What is op? The left operand is the partially filled map, and the right operand is the new letter. The result is the augmented map.It becomes the input to the next call to op, and at the end, the result is a map with all counts.```scala//  with folding, it turns toval foldingRes1 = ( Map[Char, Int]() /: "Mississippi" ) {    ( map, newchar ) => map + ( newchar -> (map.getOrElse(newchar, 0) + 1) ) }    // Map(M -> 1, i -> 4, s -> 4, p -> 2)```It is possible to replace any while loop with a fold. Build a data structure that combines all variables updated in the loop, and define an operation that implements one step through the loop. I am not saying that this is always a good idea, but you may find it interesting that loops and mutations can be eliminated in this way.  * scan  Finally, the scanLeft and scanRight methods combine folding and mapping. You get a collection of all intermediate results. For example,  ```scala(1 to 10).scanLeft(0)(_ + _)  // Vector(0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55)```#### ZippingSometimes, you have two collections, and you want to combine corresponding elements. For example, suppose you have a list of product prices andcorresponding quantities:  ```scalaval prices = List(5.0, 20.0, 9.95)val quantities = List(10, 2, 1)prices zip quantities    // List((5.0,10), (20.0,2), (9.95,1))```The zip method lets you combine them into a list of pairs. For example,prices zip quantities is a List[(Double, Int)]If one collection is shorter than the other, the result has as many pairs as the shorter collection. For example,  ```scalaList(5.0, 20.0, 9.95) zip List(10, 2)    // List((5.0, 10), (20.0, 2))List(5.0, 20.0, 9.95).zipAll(List(10, 2), 0.0, 1)  // List((5.0, 10), (20.0, 2), (9.95, 1))```The zipAll method lets you specify defaults for the shorter list  The zipWithIndex method returns a list of pairs where the second component is the index of each element.  ```scala"Scala".zipWithIndex          // Vector(('S', 0), ('c', 1), ('a', 2), ('l', 3), ('a', 4))"Scala".zipWithIndex.max      // ('l', 3)"Scala".zipWithIndex.max._2   // 3```However, `iterators are useful for collections that are expensive to construct fully`.  When you have an iterator, you can iterate over the elements with the next and hasNext methods.  ```scalawhile (iter.hasNext)  do something w ith iter.next()```If you prefer, you can use a for loop instead:  ```scalafor (elem <- iter)  do something w ith elem```here are a few Iterable methods that yield an iterator, such as **grouped** or **sliding**.#### Scala StreamsIn the preceding sections, you saw that an iterator is a “lazy” alternative to a collection. You get the elements as you need them. If you don’t need any more elements, you don’t pay for the expense of computing the remaining ones.`However, iterators are fragile. Each call to next mutates the iterator.`   Streams offer an immutable alternative. `A stream is an immutable list in which the tail is computed lazily—that is, only when you ask for it.`The #:: operator is like the :: operator for lists, but it constructs a stream```scaladef numsFrom(n: BigInt): Stream[BigInt] = n #:: numsFrom(n + 1)val tenOrMore = numsFrom(10)        // Stream(10, ?)println(tenOrMore)                  // Stream(10, ?)// The tail is unevaluated.tenOrMore.tail.tail.tail            // Stream(13, ?)    println(tenOrMore)                  // Stream(10, 11, 12, 13, ?)tenOrMore.tail.tail                 // Stream(12, 13, ?)tenOrMore.tail                      // Stream(11, 12, 13, ?)println(tenOrMore)                  // Stream(10, 11, 12, 13, ?)tenOrMore.take(3).force             // Stream(10, 11, 12)println(tenOrMore)                  // Stream(10, 11, 12, 13, ?)tenOrMore.take(5).force             // Stream(10, 11, 12, 13, 14)println(tenOrMore)                  // Stream(10, 11, 12, 13, 14, ?)tenOrMore.tail.tail                 // Stream(12, 13, 14, ?)// Stream methods are executed lazily.val squares = numsFrom(2).map { x => x * x }    // Stream(4, ?)// You have to call squares.tail to force evaluation of the next entry.squares.tail                        // Stream(9, ?)println(squares)                    // Stream(4, 9, ?)// If you want to get more than one answer, you can invoke take followed by force, // which forces evaluation of all values.squares.take(5).force               // Stream(4, 9, 16, 25, 36)```Stream methods are executed lazily.  Of course, you don’t want to call  ```scalasquares.force // No!```That call would attempt to evaluate all members of an infinite stream, causing an `OutOfMemoryError`.`You can construct a stream from an iterator`. For example, the Source.getLines method returns an Iterator[String]. With that iterator, you can only visit the lines once. A stream caches the visited lines so you can revisit them:  ```scalaval words = scala.io.Source.fromFile("src/main/scala/outerhaven/sfti/definition/testfile1.txt")              .getLines().toStreamprintln(words)          // Stream(Alpha, ?)println(words(5))       // Nariprintln(words)          // Stream(Alpha, Boy, Cat, Dio, Edin, Nari, ?)// revisit linesprintln(words(2))       // Cat```#### Lazy ViewsIn the preceding section, you saw that stream methods are computed lazily, delivering results only when they are needed. `You can get a similar effect with other collections by applying the view method. This method yields a collection on which methods are applied lazily.` For example,  ```scalaval powers = (0 until 1000).view.map(pow(10, _))```yields a collection that is unevaluated. (Unlike a stream, not even the first element is evaluated.) When you call  ```scalapowers(100)```then pow(10, 100) is computed, but the other powers are not. Unlike streams, `these views do not cache any values.` If you call powers(100) again, pow(10, 100) is recomputed.  As with streams, use the **force** method to force evaluation of a lazy view. You get back a collection of the same type as the original.  Lazy views can be beneficial if a large collection is transformed in multiple ways, because it `avoids building up large intermediate collections`. For example, compare  ```scala(0 to 1000).map(pow(10, _)).map(1 / _)```with  ```scala(0 to 1000).view.map(pow(10, _)).map(1 / _).force```The former computes a collection of the powers of 10, then applies the reciprocal to all of them. The latter computes a view that remembers both map operations. When evaluation is forced, both operations are applied to each element, `without building an intermediate collection.`The **scala.collection.JavaConversions** object provides a set of conversions between Scala and Java collections.#### Threadsafe CollectionsThe Scala library provides six traits that you can mix in with collections to synchronize their operations:  * SynchronizedBuffer* SynchronizedMap* SynchronizedPriorityQueue* SynchronizedQueue* SynchronizedSet* SynchronizedStackBefore using these mix-ins, be sure to understand what they do and do not do. In the preceding example, you can be sure that the scores map won’t be damaged—any of its operations will run to completion before another thread canexecute another operation.However, concurrently mutating or iterating over the collection is not safe and will likely lead to errors in your code.`You are generally better off using one of the classes of the java.util.concurrent package`. For example, use a ConcurrentHashMap orConcurrentSkipListMap if multiple threads share a map. These collections are more efficient than a map that simply synchronizes all its methods. Different threads can concurrently access unrelated parts of the data structure. (Don’t try implementing this at home!) Moreover, the iterators are “weakly consistent” in that they present a view that was valid when the iterator was obtained.  You can adapt the java.util.concurrent collections to Scala, as described in the preceding section.#### Parallel CollectionsIt is hard to write correct concurrent programs, yet concurrency is often required nowadays to keep all processors of a computer busy. Scala offers a particularly attractive solution for tasks that manipulate large collections. Such tasks often parallelize naturally. For example, to compute the sum of all elements, multiple threads can concurrently compute the sums of differentsections; in the end, these partial results are summed up. Of course it is troublesome to schedule these concurrent activities—but with Scala, you don’t have to. If coll is a large collection, then  ```scalacoll.par.sum```computes the sum concurrently. `The par method produces a parallel implementation of the collection. That implementation parallelizes the collection methods whenever possible`. For example,  ```scalacoll.par.count(_ % 2 == 0)```counts the even numbers in coll by evaluating the predicate on subcollections in parallel and combining the results.  For arrays, buffers, hash tables, and balanced trees, the parallel implementations reuse the implementation of the underlying collection, which is very efficient.You can parallelize a for loop by applying .par to the collection over which you iterate, like this:  ```scalafor (i <- (0 until 100).par) print(i + " ")```Try it out—the numbers are printed in the order they are produced by the threads working on the task.  `In a for/yield loop, the results are assembled in order`. Try this:  ```scalafor (i <- (0 until 100).par) yield i + " "```__Caution__  If parallel computations mutate shared variables, the result is unpredictable. For example, do not update a shared counter:  ```scalavar count = 0for (c <- coll.par) { if (c % 2 == 0) count += 1 } // count is unpredictable```The parallel collections returned by the par method belong to types that extend the `ParSeq, ParSet, or ParMap` traits, all of which are subtypes of **ParIterable**. These are not subtypes of Iterable, so you cannot pass a parallel collection to a method that expects an Iterable, Seq, Set, or Map. You can convert a parallel collection back to a serial one with the **ser** method, or you can implement methods that take parameters of generic types GenIterable, GenSeq, GenSet, or GenMap. __Note__  `Not all methods can be parallelized`. For example, reduceLeft and reduceRight require that each operator is applied in sequence. There is an alternate method, **reduce**, that operates on parts of the collection and combines the results. For this to work, `the operator must be associative`—it must fulfill (a op b) op c = a op (b op c).   For example, addition is associative but subtraction is not: (a – b) – c ≠ a – (b – c).  Similarly, there is a **fold** method that operates on parts of the collection. Unfortunately, it is not as flexible as foldLeft or foldRight—both arguments of the operator must be elements. That is, you can do coll.par.fold(0)(_ + _), but you cannot do a more complex fold such as the one at the end of Section 13.10, “Reducing, Folding, and Scanning,” on page 168.  To solve this problem, there is an even more general **aggregate** that applies an operator to parts of the collection, and then uses another operator to combine the results. For example,   ```scalastr.par.aggregate(Set[Char]())(_ + _, _ ++ _) ```is the equivalent of  ```scalastr.foldLeft(Set[Char]())(_ + _)```forming a set of all distinct characters in str.Pattern Matching and Case Classes---* The match expression is a better switch, without fall-through.* If no pattern matches, a MatchError is thrown. Use the case _ pattern to avoid that.* A pattern can include an arbitrary condition, called a guard.* `You can match on the type of an expression`; prefer this over isInstanceOf/asInstanceOf.* You can match patterns of arrays, tuples, and case classes, and bind parts of the pattern to variables.* In a for expression, nonmatches are silently skipped.* `A case class is a class for which the compiler automatically produces the methods that are needed for pattern matching.`* The common superclass in a case class hierarchy should be sealed.* Use the Option type for values that may or may not be present—it is safer than using null.[Back To Indexes](#indexes)  Here is the equivalent of the C-style switch statement in Scala:  ```scalavar sign = 0val ch: Char = '+'ch match {  case '+' => sign = 1  case '-' => sign = -1  case _ => sign = 0}```The equivalent of default is the catch-all case _ pattern. It is a good idea to have such a catch-all pattern. If no pattern matches, a MatchError is thrown.Unlike the switch statement, Scala pattern matching does not suffer from the “fall-through” problem.Similar to if, match is an expression, not a statement.You can use the match statement with any types, not just numbers.`In Scala, you add a guard clause to a pattern`, like this:  ```scalavar sign = 0val ch: Char = '+'var digit: Int = 0 ch match {  case _ if Character.isDigit(ch) => digit = Character.digit(ch, 10)  case _ => sign = 0}```#### Type Patterns```scalaval obj: Any = 1obj match {  case x: Int => x  case s: String => Integer.parseInt(s)  case _: BigInt => Int.MaxValue  case _ => 0} ```When you match against a type, you must supply a variable name. Otherwise, you match the object:  ```scalaobj match {  case _: BigInt => Int.MaxValue // Matches any object of type BigInt  case BigInt => -1 // Matches the BigInt object of type Class}```Matches occur at runtime, and generic types are erased in the Java virtual machine. For that reason, you cannot make a type match for a specific Map type.  ```scalacase m: Map[String, Int] => ... // Don't// You can match a generic map:case m: Map[_, _] => ... // OK```However, arrays are not erased. You can match an Array[Int].  To match an array against its contents, use Array expressions in the patterns, like this:  ```scalaval arr = Array(0, 1, 3, 6)arr match {  case Array(0) => "0"  case Array(x, y) => x + " " + y  case Array(0, _*) => "0 ..."  case _ => "something else"}```In the preceding section, you have seen how patterns can match arrays, lists, and tuples. `These capabilities are provided by extractors—objects with an unapply or unapplySeq method that extract values from an object`. The implementation of these methods is covered in Chapter 11. The **unapply** method is provided to extract a fixed number of objects, while **unapplySeq** extracts a sequence whose length can vary.  Regular expressions provide another good use of extractors. When a regular expression has groups, you can match each group with an extractor pattern. For example:  ```scalaval pattern = "([0-9]+) ([a-z]+)".r  "99 bottles" match {  case pattern(num, item) => ...  // Sets num to "99", item to "bottles"}``````scalaval (q, r) = BigInt(10) /% 3```The /% method returns a pair containing the quotient and the remainder, which are captured in the variables q and r.#### Case ClassesWhen you declare a case class, several things happen automatically.  * Each of the constructor parameters becomes a val unless it is explicitly declared as a var (which is not recommended).* An apply method is provided for the companion object that lets you construct objects without new, such as Dollar(29.95) or Currency(29.95, "EUR").* An unapply method is provided that makes pattern matching work* Methods toString, equals, hashCode, and copy are generated unless they are explicitly provided.  Otherwise, case classes are just like any other classes. You can add methods and fields to them, extend them, and so on.#### The copy Method and Named Parameters```scalaval amt = Currency(29.95, "EUR")var price = amt.copy()          // Currency(29.95, "EUR")price = amt.copy(value = 19.95) // Currency(19.95, "EUR")price = amt.copy(unit = "CHF") // Currency(29.95, "CHF")```#### Infix Notation in case Clauses  When an unapply method yields a pair, you can use infix notation in the case clause. In particular, you can use infix notation with a case class that has two parameters. For example:  ```scalaamt match { case a Currency u => ... } // Same as case Currency(a, u)```For example, every List object is either Nil or an object of the case class ::, defined as  ```scalacase class ::[E](head: B, tail: List[E]) extends List[E]```Therefore, you can write  ```scalalst match { case h :: t => ... }// Same as case ::(h, t), which calls ::.unapply(lst)``````scala// ~ case class for combining pairs of parse results.result match { case p ~ q => ... } // Same as case ~(p, q)result match { case p ~ q ~ r => ... } // is nicer than ~(~(p, q), r).```#### Matching Nested StructuresCase classes are often used for nested structures.```scalaabstract class Itemcase class Article(description: String, price: Double) extends Itemcase class Bundle(description: String, discount: Double, items: Item*) extends Itemval item = Bundle("Father's day special", 20.0,  Article("Scala for the Impatient", 39.95),  Bundle(  "Anchor Distillery Sampler", 10.0,           Article("Old Potrero Straight Rye Whiskey", 79.95),           Article("Junípero Gin", 32.95)))item match {  case Bundle(_, _, Article(descr, _), _*) => println(descr)  // You can bind a nested value to a variable with the @ notation  case Bundle(_, _, art @ Article(_, _), rest @ _*) => println(art.description)  case _ => println("no match")}``````scaladef priceCalc(it: Item): Double = it match {  case Article(_, p) => p  case Bundle(_, disc, its @ _*) => its.map(priceCalc _).sum - disc}```The example in the preceding section can enrage OO purists. Shouldn’t priceCalc be a method of the superclass? Shouldn’t each subclass override it? Isn’t polymorphism better than making a switch on each type?  In many situations, this is true. `If someone comes up with another kind of Item, one needs to revisit all those match clauses. In such a situation, case classes are not the right solution.`  `Case classes work well for structures whose makeup doesn’t change`. For example, the Scala List is implemented with case classes. Simplifying things a bit, a list is essentially  ```scalaabstract class Listcase object Nil extends Listcase class ::(head: Any, tail: List) extends List```A list is either empty, or it has a head and a tail (which may be empty or not). Nobody is ever going to add a third case. (You’ll see in the next section how to stop anyone from trying.)For certain kinds of classes, case classes give you exactly the right semantics. Some people call them value classes. Typically, such classes are immutable.#### Sealed ClassesWhen you use `pattern matching with case classes`, you would like the compiler to check that you exhausted all alternatives. You achieve this by declaring the common superclass as sealed:  ```scalasealed abstract class Amountcase class Dollar(value: Double) extends Amountcase class Currency(value: Double, unit: String) extends Amount````All subclasses of a sealed class must be defined in the same file as the class itself`. When a class is sealed, all of its subclasses are known at compile time, enabling the compiler to check pattern clauses for completeness. It is a good idea for all case classes to extend a sealed class or trait.#### The Option TypeThe Option type in the standard library uses case classes to express values that might or might not be present. The case subclass **Some** wraps a value, for example Some("Fred"). The case object **None** indicates that there is no value.  If you want to skip a None value, use a for comprehension  ```scalafor (score <- scores.get("Alice")) println(score)```You can also consider an Option to be a collection that is either empty or has one element, and use methods such as map, foreach, or filter.#### Partial FunctionsA set of case clauses enclosed in braces is a partial function—a function which may not be defined for all inputs. It is an instance of a class `PartialFunction[A, B]`. (A is the parameter type, B the return type.) That class has two methods: **apply**, which computes the function value from the matching pattern, and **isDefinedAt**, which returns true if the input matches at least one of the patterns.```scalaval f: PartialFunction[Char, Int] = { case '+' => 1 ; case '-' => -1 }f('-') // Calls f.apply('-'), returns -1f.isDefinedAt('0') // falsef('0') // Throws MatchError```Some methods accept a PartialFunction as a parameter. For example, the **collect** method of the GenTraversable trait applies a partial function to all elements where it is defined, and returns a sequence of the results.  ```scala"-3+4".collect { case '+' => 1 ; case '-' => -1 } // Vector(-1, 1)```Annotations---* You can annotate classes, methods, fields, `local variables`, parameters, `expressions`, `type parameters`, and `types`.* `With expressions and types, the annotation follows the annotated item`.* Annotations have the form @Annotation, @Annotation(value), or @Annotation(name1 = value1, ...).* @volatile, @transient, @strictfp, and @native generate the equivalent Java modifiers.* Use @throws to generate Java-compatible throws specifications.* `The @tailrec annotation lets you verify that a recursive function uses tail call optimization`.* The assert function takes advantage of the @elidable annotation. You can optionally remove assertions from your Scala programs.* Use the @deprecated annotation to mark deprecated features.[Back To Indexes](#indexes)  When annotating the primary constructor, place the annotation before the constructor, and add a set of parentheses if the annotation has no arguments.  ```scalaclass Credentials @Inject() (var username: String, var password: String)```You can also annotate expressions. Add a colon followed by the annotation, for example:  ```scala(myMap.get(key): @unchecked) match { ... }// The expression myMap.get(key) is annotated```You can annotate type parameters:  ```scalaclass MyContainer[@specialized T]```Annotations on an actual type are placed after the type, like this:  ```scalaString @cps[Unit] // The @cps has a type parameter```Here, the String type is annotated.An (scala) annotation must extend the Annotation trait. An annotation class can optionally extend the StaticAnnotation or ClassfileAnnotation trait.If you call a Scala method from Java code, its signature should include the checked exceptions that can be thrown. Use the @throws annotation to generate the correct signature. For example,  ```scalaclass Book {@throws(classOf[IOException]) def read(filename: String) { //... }}```The @varargs annotation lets you call a Scala variable-argument method from Java. By default, if you supply a method such as   ```scaladef process(args: String*)```the Scala compiler translates the variable argument into a sequence  ```scaladef process(args: Seq[String])```That is cumbersome to use in Java. If you add @varargs,  ```scala@varargs def process(args: String*)```then a Java method  ```scalavoid process(String... args) // Java bridge method```is generated that wraps the args array into a Seq and calls the Scala method.#### Annotations for Optimizations* @tailrec Tail Recursion  A recursive call can sometimes be turned into a loop, which conserves stack space. This is important in functional programming where it is common to write recursive methods for traversing collections.  A more general mechanism for recursion elimination is “trampolining”.* @switch  In C++ or Java, a switch statement can often be compiled into a jump table, which is more efficient than a sequence of if/else expressions. Scala attempts to generate jump tables for match clauses as well.* @inline and @noinlineThe @elidable annotation flags methods that can be removed in production code.For example,  ```scala@elidable(500) def dump(props: Map[String, String]) { ... }```If you compile with `scalac -Xelide-below 800 myprog.scala`, then the method code will not be generated.#### Specialization for Primitive TypesIt is inefficient to wrap and unwrap primitive type values—but in generic code, this often happens. Consider, for example,  ```scaladef allDifferent[T](x: T, y: T, z: T) = x != y && x != z && y != z```If you call allDifferent(3, 4, 5), each integer is wrapped into a java.lang.Integer before the method is called. Of course, one canmanually supply an overloaded version   ```scaladef allDifferent(x: Int, y: Int, z: Int) = ...```as well as seven more methods for the other primitive types.  You can generate these methods automatically by annotating the type parameter with @specialized:```scaladef allDifferent[@specialized T](x: T, y: T, z: T) = ...//You can restrict specialization to a subset of types:def allDifferent[@specialized(Long, Double) T](x: T, y: T, z: T) = ...```XML Processing---* `XML literals <like>this</like> are of type NodeSeq`.* `You can embed Scala code inside XML literals`.* The child property of a Node yields the child nodes.* The attributes property of a Node yields a MetaData object containing the node attributes.* `The \ and \\ operators carry out XPath-like matches`.* You can match node patterns with XML literals in case clauses.* Use the RuleTransformer with RewriteRule instances to transform descendants of a node.* The XML object interfaces with Java XML methods for loading and saving.* The ConstructingParser is an alternate parser that preserves comments and CDATA sections.[Back To Indexes](#indexes)  #### XML LiteralsYou can define XML literals, simply by using the XML code:  ```scalaval doc = <html><head><title>Fred's Memoirs</title></head><body>...</body></html>```In this case, doc becomes a value of type `scala.xml.Elem`, representing an XML element.  An XML literal can also be a sequence of nodes. For example,  ```scalaval items = <li>Fred</li><li>Wilma</li>```yields a `scala.xml.NodeSeq`.![scala_xml_node_types_img_1]  Node sequences are of type NodeSeq, a subtype of Seq[Node] that adds support for XPath-like operators (see Section 16.7, “XPathlike Expressions,” on page 220). You can use any of the Seq operations described in Chapter 13 with XML node sequences.The Node class extends NodeSeq. A single node is a sequence of length 1. This is supposed to make it easier to deal with functions that can return a single node or a sequence. (It actually creates as many problems as it solves, so I don’t recommend using this trick in your own designs.)#### Embedded ExpressionsYou can include blocks of Scala code inside XML literals to dynamically compute items. For example:  ```scala<ul><li>{items(0)}</li><li>{items(1)}</li></ul>```**Text** is a subclass of Atom[String]. It doesn’t matter when saving a document. But if you later do pattern matching on Text nodes, the match will fail. In that case, you should insert Text nodes instead of strings:  ```scala<li>{Text("Another item")}</li>```#### XPath-like ExpressionsThe NodeSeq class provides methods that resemble the / and // operators in XPath (XML Path Language, www.w3.org/TR/xpath). Since // denotes comments and is therefore not a valid operator, `Scala uses \ and \\ instead`.   The \ operator locates direct descendants of a node or node sequence. For example,```scalaval list = <dl><dt>Java</dt><dd>Gosling</dd><dt>Scala</dt><dd>Odersky</dd></dl>val languages = list \ "dt"```sets languages to a node sequence containing ```scala<dt>Java</dt> <dt>Scala</dt>```A **wildcard** matches any element. For example,```scaladoc \ "body" \ "_" \ "li"```The \\ operator locates descendants at any depth. For example,  ```scaladoc \\ "img"```Unlike XPath, you cannot use a single \ to extract attributes from multiple nodes. For example, ```scaladoc \\ "img" \ "@src" ```will not work if the document contains more than one img element. Use ```scaladoc \\ "img" \\ "@src" ```instead.You can use XML literals in pattern matching expressions. For example,```scalanode match {  case <img/> => ...  ...}```#### Modifying Elements and AttributesIn Scala, XML nodes and node sequences are immutable. If you want to edit a node, you have to create a copy of it, making any needed changes and copying what hasn’t changed.```scalaval list = <ul><li>Fred</li><li>Wilma</li></ul>val list2 = list.copy(label = "ol")val list1 = <ul><li>Fred</li><li>Wilma</li></ul>val list2 = list1.copy(label = "ol")// To add a child, make a call to copy like this:list1.copy(child = list1.child ++ <li>Another item</li>)// To add or change an attribute, use the % operator:val image = <img src="hamster.jpg"/>val image2 = image % Attribute(null, "alt", "An image of a hamster", Null)val image3 = image % Attribute(null, "alt", "An image of a frog",  Attribute(null, "src", "frog.jpg", Null))```#### Transforming XMLSometimes, you need to rewrite all descendants that match a particular condition. The XML library provides a **RuleTransformer** class that applies one or more **RewriteRule** instances to a node and its descendants.  ```scalaval rule1 = new RewriteRule {  override def transform(n: Node) = n match {    case e @ <ul>{ _* }</ul> => e.asInstanceOf[Elem].copy(label = "ol")    case _ => n  }}val transformed = new RuleTransformer(rule1).transform(root)```To load an XML document from a file, call the loadFile method of the XML object:```scalaimport scala.xml.XMLval root = XML.loadFile("myfile.xml")val root2 = XML.load(new FileInputStream("myfile.xml"))val root3 = XML.load(new InputStreamReader(new FileInputStream("myfile.xml"), "UTF-8"))val root4 = XML.load(new URL("http://horstmann.com/index.html"))```This parser suffers from a problem that is inherited from the Java library. It does not read DTDs from a local catalog. In particular, fetching an XHTML file can take a very long time, or fail altogether, when the parser retrieves the DTDs from the w3c.org site.  To use a local catalog, you need the **CatalogResolver** class that is available in the com.sun.org.apache.xml.internal.resolver.toolspackage of the JDK, or, if you are squeamish about using a class outside the official API, from the Apache Commons Resolver project (http://xml.apache.org/commons/components/resolver/resolver-article.html).  Unfortunately, the XML object has no API for installing an entity resolver. Here is how you can do it through the back door:  ```scalaval res = new CatalogResolverval doc = new factory.XMLLoader[Elem] {  override def adapter = new parsing.NoBindingFactoryAdapter() {    override def resolveEntity(publicId: String, systemId: String) = {    res.resolveEntity(publicId, systemId)    }  }}.load(new URL("http://horstmann.com/index.html"))```There is another parser that preserves comments, CDATA sections, and, optionally, whitespace: **ConstructingParser**If you happen to read an XHTML file, you can use the **XhtmlParser** subclass  To save an XML document to a file, use the save method:  ```scalaXML.save("myfile.xml", root)// You can also save to a java.io.Writer, but then you must specify all parameters.XML.write(writer, root, "UTF-8", false, null)```When saving an XML file, elements without content are not written with self-closing tags. For example:  ```xml<img src="hamster.jpg"></img>```If you prefer```scala<img src="hamster.jpg"/>```use  ```scalaval str = xml.Utility.toXML(node, minimizeTags = true)```If you want your XML code to line up prettily, use the PrettyPrinter class:```scalaval printer = new PrettyPrinter(width = 100, step = 4)val str = printer.formatNodes(nodeSeq)```Type Parameters---In Scala, you specify how your types should vary depending on their parameters.  * Classes, traits, methods, and functions can have type parameters.* Place the type parameters after the name, enclosed in square brackets.* `Type bounds have the form T <: UpperBound, T >: LowerBound, T <% ViewBound, T : ContextBound`.* You can restrict a method with a type constraint such as (implicit ev: T <:< UpperBound).* Use +T (covariance) to indicate that a generic type’s subtype relationship is in the same direction as the parameter T, or -T (contravariance) to indicate the reverse direction.* Covariance is appropriate for parameters that denote outputs, such as elements in an immutable collection.* Contravariance is appropriate for parameters that denote inputs, such as function arguments.[Back To Indexes](#indexes)  ```scalaclass Pair[T](val first: T, val second: T) {  def smaller = if (first.compareTo(second) < 0) first else second // Error}```That’s wrong—we don’t know if first has a compareTo method. To solve this, we can add an upper bound T <: Comparable[T].```scalaclass Pair[T <: Comparable[T]](val first: T, val second: T) {  def smaller = if (first.compareTo(second) < 0) first else second}```This means that T must be a subtype of Comparable[T].__View Bound__  Unfortunately, if you try constructing a new Pair(4, 2), the compiler complains that Int is not a subtype of Comparable[Int]. Unlike the java.lang.Integer wrapper type, the Scala Int type does not implement Comparable. However, RichInt does implement Comparable[Int], and there is an implicit conversion from Int to RichInt.   The solution is to use a “view bound” like this:  ```scalaclass Pair[T <% Comparable[T]]````The <% relation means that T can be converted to a Comparable[T] through an implicit conversion`.It is nicer to use the Ordered trait which adds relational operators to Comparable:  ```scalaclass Pair[T <% Ordered[T]](val first: T, val second: T) {  def smaller = if (first < second) first else second}```__Context Bounds__  A view bound T <% V requires the existence of an implicit conversion from T to V. A context bound has the form T : M, where M is another generic type. It requires that there is an “implicit value” of type M[T]. For example,```scalaclass Pair[T : Ordering]```requires that there is an implicit value of type Ordering[T].   That implicit value can then be used in the methods of the class. Whenyou declare a method that uses the implicit value, you have to add an “implicit parameter.” Here is an example:```scalaclass Pair[T : Ordering](val first: T, val second: T) {  def smaller(implicit ord: Ordering[T]) =  if (ord.compare(first, second) < 0) first else second}```As you will see in Chapter 21, `implicit values are more flexible than implicit conversions`.__Lower Bound__  In general, the replacement type must be a supertype of the pair’scomponent type.```scaladef replaceFirst[R >: T](newFirst: R) = new Pair[R](newFirst, second)```Here, I included the type parameter in the returned pair for greater clarity. You can also write```scaladef replaceFirst[R >: T](newFirst: R) = new Pair(newFirst, second)```Then the return type is correctly inferred as new Pair[R].If you omit the lower bound, ```scaladef replaceFirst[R](newFirst: R) = new Pair(newFirst, second)```the method will compile, but it will return a Pair[Any].#### The Manifest Context BoundTo instantiate a generic Array[T], one needs a Manifest[T] object. This is required for primitive type arrays to work correctly. For example, if T is Int, you want an int[] array in the virtual machine. Since it’s an implicit parameter of the constructor, you can use a context bound, like this```scaladef makePair[T : Manifest](first: T, second: T) = {  val r = new Array[T](2); r(0) = first; r(1) = second; r}```If you call makePair(4, 9), the compiler locates the implicit Manifest[Int] and actually calls makePair(4, 9)(intManifest). Then the method calls new Array(2)(intManifest), which returns a primitive array int[2].#### Type ConstraintsType constraints give you another way of restricting types. There are three relationships that you can use:  * T =:= U  * T <:< U  * T <%< U  These constraints test whether T equals U, is a subtype of U, or is view-convertible to U. `To use such a constraint, you add an “implicit evidence parameter” like this`:  ```scalaclass Pair[T](val first: T, val second: T)(implicit ev: T <:< Comparable[T])```__two uses of type constraints__  1. Type constraints let you supply a method in a generic class that can be used only under certain conditions  ```scalaclass Pair[T](val first: T, val second: T) {  def smaller(implicit ev: T <:< Ordered[T]) =  if (first < second) first else second}```You can form a Pair[File], even though File is not ordered, however, You will get an error only if you invoke the smaller method.2. Another use of type constraints is for improving type inference  ```scaladef firstLast[A, C <: Iterable[A]](it: C) = (it.head, it.last)When you callfirstLast(List(1, 2, 3))```you get a message that the inferred type arguments [Nothing, List[Int]] don’t conform to [A, C <: Iterable[A]]. Why Nothing? The type inferencer cannot figure out what A is from looking at List(1, 2, 3), `because it matches A and C in a single step`. To help it along, `first match C and then A`:  ```scaladef firstLast[A, C](it: C)(implicit ev: C <:< Iterable[A]) =  (it.head, it.last)```You saw a similar trick in Chapter 12, with curried parameter```scaladef corresponds[B](that: Seq[B])(match: (A, B) => Boolean): BooleanArray("Hello", "Fred").corresponds(Array(5, 4))(_.length == _)//the compiler can infer that B is Int. Then it can make sense of _.length == _.```The match predicate is a curried parameter so that the type inferencer can first determine the type of B and then use that information to analyze match. #### Scala VarianceSuppose we have a function that does something with a Pair[Person]:  ```scaladef makeFriends(p: Pair[Person])```If Student is a subclass of Person, can I call makeFriend with a Pair[Student]? By default, this is an error. Even though Student is a subtype of Person, there is no relationship between Pair[Student] and Pair[Person].__Covariant__  If you want such a relationship, you have to indicate it when you define the Pair class:  ```scalaclass Pair[+T](val first: T, val second: T)```The + means that the type is covariant in T—that is, it varies in the same direction. Since Student is a subtype of Person, a Pair[Student] is now a subtype of Pair[Person].  __Contravariant__  Now suppose you have a function```scalatrait Friend[-T] {  def befriend(someone: T)}def makeFriendWith(s: Student, f: Friend[Student]) { f.befriend(s) }```Can you call it with a Friend[Person]? Yes, you can  ```scalaclass Person extends Friend[Person]class Student extends Personval susan = new Studentval fred = new Person```If Fred is willing to befriend any person(Friend[Person]), he’ll surely like tobe friends with Susan(Friend[Student]). (An easy way to understand contravariant)   Note that the type varies in the opposite direction of the subtype relationship. Student is a subtype of Person, but Friend[Person] is a supertype of Friend[Student]. __Covariant + Contravariant__  You can have both variance types in a single generic type. For example, any single-argument functions have the type `Function1[-A, +R]`(PS: though weird, it is trait scala.Functoin1). To see why these are the appropriate variances, consider a function  ```scaladef friends(students: Array[Student], find: Function1[Student, Person]) =  // You can write the second parameter as find: Student => Person  for (s <- students) yield find(s)```Suppose you have a function  ```scaladef findStudent(p: Person) : Student```Can you call friends with that function? Of course you can.   It’s willing to take any person, so surely it will take a Student.  It yields Student results, which can be put into an Array[Person].  In the preceding section, you saw that functions are contravariant in their arguments and covariant in their results. Generally, it makes sense to use contravariance for the values an object consumes, and covariance for the values it produces. These are "Covariant and Contravariant Positions"If they are used in wrong positions, there would be compilation error.#### Scala Invariant  Generally, it makes sense to use contravariance for the values an object consumes, and covariance for the values it produces.  If an object does both, then the type should be left **invariant**. This is generally the case for mutable data structures. For example, in Scala, arrays are invariant. You can’t convert an Array[Student] to an Array[Person] or the other way around. This would not be safe. Consider the following:  ```scalaval students = new Array[Student](length)val people: Array[Person] = students // Not legal, but suppose it was.people(0) = new Person("Fred") // Oh no! Now students(0) isn't a Student```Conversely,   ```scalaval people = new Array[Person](length)val students: Array[Student] = people // Not legal, but suppose it was.people(0) = new Person("Fred") // Oh no! Now students(0) isn't a Student```Supposed Student is a subtype of Person, In Java, it is possible to convert a Student[] array to a Person[] array, but if you try to add a nonstudent into such an array, an ArrayStoreException is thrown. In Scala, the compiler rejects programs that could cause type errors.In Java, all generic types are invariant.In Scala, you don’t need the wildcard for a covariant Pair class. But suppose Pair is invariant:  ```scalaclass Pair[T](var first: T, var second: T)```PS: This indicates that, if a typed parameter is not either covariant or contravariant, it is invariant.You can’t add a parameterized type to an object  ```scalaobject Empty[T] extends List[T] // Error```In this case, a remedy is to inherit List[Nothing]:  ```scalaobject Empty extends List[Nothing]```Recall from Chapter 8 that the **Nothing** type is a subtype of all types.#### Scala WildcardsIn Java, all generic types are invariant. However, you can vary the types where you use them, using wildcards. For example, a method```scalavoid makeFriends(List<? extends Person> people) // This is Java```can be called with a List<Student>.  You can use wildcards in Scala too. They look like this:  ```scaladef process(people: java.util.List[_ <: Person]) // This is Scala```In Scala, you don’t need the wildcard for a covariant Pair class. But suppose Pair is invariant:  ```scalaclass Pair[T](var first: T, var second: T)```Then you can define  ```scaladef makeFriends(p: Pair[_ <: Person]) // OK to call with a Pair[Student]```You can also use wildcards for contravariance:  ```scalaimport java.util.Comparatordef min[T](p: Pair[T])(comp: Comparator[_ >: T])```Wildcards are “syntactic sugar” for existential types, which we will discuss in detail in Chapter 18.Advanced Types---* Singleton types are useful for method chaining and methods with object parameters.* A type projection includes inner class instances for all objects of an outer class.* A type alias gives a short name for a type.* Structural types are equivalent to “duck typing.”* Existential types provide the formalism for wildcard parameters of generic types.* Use a self type declaration to indicate that a trait requires another type.* The “cake pattern” uses self types to implement a dependency injection mechanism.* An abstract type must be made concrete in a subclass.* A higher-kinded type has a type parameter that is itself a parameterized type.[Back To Indexes](#indexes)  #### Singleton TypesGiven any reference v, you can form the type v.type, which has two values: v and null. This sounds like a curious type, but it has a couple of useful applications.1. consider a method that returns this so you can chain method calls  ```scalaclass Document {  def setTitle(title: String) = { ...; this }  def setAuthor(author: String) = { ...; this }  //...}```You can then call  ```scalaarticle.setTitle("Whatever Floats Your Boat").setAuthor("Cay Horstmann")```However, if you have a subclass, there is a problem:  ```scalaclass Book extends Document {  def addChapter(chapter: String) = { ...; this }  //...}val book = new Book()book.setTitle("Scala for the Impatient").addChapter(chapter1) // Error```Since the setTitle method returns this, Scala infers the return type as Document. But Document doesn’t have an addChapter method.  The remedy is to declare the return type of setTitle as this.type:  ```scaladef setTitle(title: String): this.type = { ...; this }```Now the return type of book.setTitle("...") is book.type, and since book has an addChapter method, the chaining works.2. to define a method that takes an **object** instance as parameter  ```scalaobject Titleclass Document {  def set(obj: Title.type): this.type = { useNextArgAs = obj; this }  //...}```Note the Title.type parameter. You can’t use  ```scaladef set(obj: Title) ... // Error```since Title denotes the singleton object, not a type.#### Type projection```scalaimport scala.collection.mutable.ArrayBufferclass Network {  class Member(val name: String) {    val contacts = new ArrayBuffer[Member]  }  private val members = new ArrayBuffer[Member]  def join(name: String) = {    val m = new Member(name)    members += m    m  }}```Each network instance has its own Member class. For example, here are two networks:  ```scalaval chatter = new Networkval myFace = new Network```Now chatter.Member and myFace.Member are different classes.  You can’t add a member from one network to another:  ```scalaval fred = chatter.join("Fred") // Has type chatter.Memberval barney = myFace.join("Barney") // Has type myFace.Memberfred.contacts += barney // Error```To fix this,  1. You should simply move the Member type outside the Network class. A good place would be the Network companion object.  2. use a type projection Network#Membe  If what you want is fine-grained classes, with an occasional loose interpretation, use a type projection Network#Member, which means “a Member of any Network.”  ```scalaclass Network {  class Member(val name: String) {    val contacts = new ArrayBuffer[Network#Member]  }  //...}```Type projection OuterClass#InnerClass, which means “a InnerClass of any OuterClass.”  A type projection such as OuterClass#InnerClass is not considered a “path,” and you cannot import it. We discuss paths in the next section.#### Scala PathsConsider a type such as```scalacom.horstmann.impatient.chatter.Member```or, if we nest Member inside the companion object,```scalacom.horstmann.impatient.Network.Member```Such an expression is called a path.  Each component of the path before the final type must be “stable,” that is, it must specify a single, definite scope. Each such component is one of the following:  1. A package2. An object3. A val4. this, super, super[S], C.this, C.super, or C.super[S]Moreover, a path element can’t be a var. For example,  ```scalavar chatter = new Networkval fred = new chatter.Member // Error—chatter is not stable```Internally, the compiler translates all nested type expressions a.b.c.T to type projections a.b.c.type#T. For example, chatter.Member becomes chatter.type#Member—any Member inside the singleton chatter.type.#### Type AliasesYou can create a simple alias for a complicated type with the type keyword, like this:  ```scalaclass Book {  import scala.collection.mutable._  type Index = HashMap[String, (Int, Int)]  //...}```Then you can refer to Book.Index instead of the cumbersome type scala.collection.mutable.HashMap[String, (Int, Int)].  A type alias must be nested inside a class or object.The type keyword is also used for abstract types that are made concrete in a subclass, for example:  ```scalaabstract class Reader {  type Contents  def read(fileName: String): Contents}```#### Structural TypesA “structural type” is a specification of abstract methods, fields, and types that a conforming type should possess. For example, this method has a structural type parameter:  ```scaladef appendLines(target: { def append(str: String): Any },                  lines: Iterable[String]) {  for (l <- lines) { target.append(l); target.append("\n") }}```You can call the appendLines method with an instance of any class that has an append method. This is more flexible than defining a Appendable trait, because you might not always be able to add that trait to the classes you are using.`Under the hood, Scala uses reflection to make the calls to target.append(...). However, a reflective call is much more expensive than a regular method call.` For that reason, you should only use structural typing when you model common behavior from classes that cannot share a trait.#### Compound TypesA compound type has the form  ```scalaT1 with T2 with T3 ...```where T1, T2, T3, and so on are types. In order to belong to the compound type, a value must belong to all of the individual types. Therefore, such a type is also called an intersection type. You can use a compound type to manipulate values that must provide multiple traits. For example,  ```scalaval image = new ArrayBuffer[java.awt.Shape with java.io.Serializable]```You can add a **structural type** declaration to a simple or compound type. For example,  ```scalaShape with Serializable { def contains(p: Point): Boolean }```An instance of this type must be a subtype of Shape and Serializable, and it must have a contains method with a Point parameter.  Technically, the structural type  ```scala{ def append(str: String): Any }```is an abbreviation for  ```scalaAnyRef { def append(str: String): Any }```and the compound type  ```scalaShape with Serializable```is a shortcut for  ```scalaShape with Serializable {}```An **infix type** is a type with two type parameters, written in “infix” syntax, with the type name between the type parameters. For example, you can write  ```scalaString Map Int```instead of```scalaMap[String, Int]```The infix notation is common in mathematics. For example, A × B = {(a, b) | a ε A, b ε B } is the set of pairs with components of types A and B. In Scala, this type is written as (A, B). If you prefer the mathematical notation, you can define  ```scalatype ×[A, B] = (A, B)```Then you can write String × Int instead of (String, Int).#### Existential TypesExistential types were added to Scala for compatibility with Java wildcards. An existential type is a type expression followed by forSome { ... }, where the braces contain type and val declarations. For example,  ```scalaArray[T] forSome { type T <: JComponent }```This is the same as the wildcard type```scalaArray[_ <: JComponent]```Scala wildcards are syntactic sugar for existential types. For example,  ```scalaArray[_]```is the same as```scalaArray[T] forSome { type T }```and```scalaMap[_, _]```is the same as```scalaMap[T, U] forSome { type T; type U }```The forSome notation allows for more complex relationships than wildcards can express, for example   ```scalaMap[T, U] forSome { type T; type U <: T }```#### Self TypesYou define the trait with a self type declaration:  ```scalathis: Type =>```Such a trait can only be mixed into a subclass of the given type.If you want to require multiple types, use a compound type:  ```scalathis: T with U with ... =>```#### Abstract TypesA class or trait can define an abstract type that is made concrete in a subclass. For example:```scalatrait Reader {  type Contents  def read(fileName: String): Contents}```Here, the type Contents is abstract. A concrete subclass needs to specify the type:  ```scalaclass StringReader extends Reader {  type Contents = String  def read(fileName: String) = Source.fromFile(fileName, "UTF-8").mkString}```The same effect could be achieved with a type parameter:   ```scalatrait Reader[C] {  def read(fileName: String): C}class StringReader extends Reader[String] {  def read(fileName: String) = Source.fromFile(fileName, "UTF-8").mkString}```But abstract types can work better when there are many type dependencies—you avoid long lists of type parameters.#### Higher-Kinded TypesNow an Iterable depends on a type constructor for the result, denoted as C[_]. This makes Iterable a higher-kinded type.  ```scalatrait Iterable[E, C[_]] {  def iterator(): Iterator[E]  def build[F](): C[F]  def map[F](f : (E) => F) : C[F]}class Range extends Iterable[Int, Buffer]```Note that the second parameter is the type constructor Buffer```scalatrait Iterable[E, C[X] <: Container[X]] {  def build[F](): C[F]  //...}class Range(val low: Int, val high: Int) extends Iterable[Int, Buffer]```Parsing---In this chapter, you will see how to use the “combinator parser” library to analyze data with fixed structure. Examples of such data are programs in a programming language or data in formats such as HTTP or JSON.  If you are familiar with the basic concepts of grammars and parsers, glance through the chapter anyway because the Scala parser library is a good example of a sophisticated domain-specific language embedded in the Scala language.* Alternatives, concatenation, options, and repetitions in a grammar turn into |, ~, opt, and rep in Scala combinator parsers.* With RegexParsers, literal strings and regular expressions match tokens.* Use ^^ to process parse results.* Use pattern matching in a function supplied to ^^ to take apart ~ results.* Use `~> and <~` to discard tokens that are no longer needed after matching.* The repsep combinator handles the common case of repeated items with a separator.* A token-based parser is useful for parsing languages with reserved words and operators. Be prepared to define your own lexer.* Parsers are functions that consume a reader and yield a parse result: success, failure, or error.* The Failure result provides the details for error reporting.* You may want to add failure clauses to your grammar to improve the quality of error messages.* Thanks to operator symbols, implicit conversions, and pattern matching, the parser combinator library makes parser writing easy for anyone who understands context-free grammars. Even if you don’t feel the urge to write your ownparsers, you may find this an interesting case study for an effective domain-specific language.[Back To Indexes](#indexes)  A grammar is usually written in a notation called Backus-Naur Form (BNF)  The most often used “extended Backus-Naur form,” or EBNF, allows specifying optional elements and repetition. I will use the familiar regex operators ? * + for 0 or 1, 0 or more, 1 or more, correspondingly.```scalaop ::= "+" | "-" | "*"expr ::= number | expr op expr | "(" expr ")"```Note that op and expr are not tokens. They are structural elements that were invented by the author of the grammar, in order to produce correct token sequences. Such symbols are called nonterminal symbols. One of the nonterminal symbols is at the root of the hierarchy; in our case, that is expr. It is called the **start symbol**. To produce correctly formatted strings, you start with the start symbol and apply the grammar rules until all nonterminals have been replaced and only tokens remain.`To use the Scala parsing library, provide a class that extends the Parsers trait and defines parsing operations that are combined from primitive operations`, such as  * Matching a token* Choosing between two operations (|)* Performing two operations in sequence (~)* Repeating an operation (rep)* Optionally performing an operation (opt)```scalaclass ExprParser extends RegexParsers {  val number = "[0-9]+".r  def expr: Parser[Any] = term ~ opt(("+" | "-") ~ expr)  def term: Parser[Any] = factor ~ rep("*" ~ factor)  def factor: Parser[Any] = number | "(" ~ expr ~ ")"}val parser = new ExprParserval result = parser.parseAll(parser.expr, "3-4*5")if (result.successful) println(result.get)```The output of the program snippet is  ```scala((3~List())~Some((-~((4~List((*~5)))~None))))```The parseAll method receives the method to be invoked—that is, the method associated with the grammar’s start symbol—and the string to be parsed.Instead of having a parser build up a complex structure of ~, options, and lists, you should `transform intermediate outputs` to a useful form.```scaladef factor: Parser[Int] = number ^^ { _.toInt } | ...```Here, the ^^ operator applies the function { _.toInt } to the result of number.```scaladef factor: Parser[Int] = ... | "(" ~ expr ~ ")" ^^ {  case _ ~ e ~ _ => e}def expr: Parser[Int] = term ~ opt(("+" | "-") ~ expr) ^^ {case t ~ None => tcase t ~ Some("+" ~ e) => t + ecase t ~ Some("-" ~ e) => t - e}def term: Parser[Int] = factor ~ rep("*" ~ factor) ^^ {  case f ~ r => f * r.map(_._2).product}```Finally, to multiply the factors, `note that rep("*" ~ factor) yields a List of items of the form "*" ~ f`, where f is an Int. We extract the second component of each ~ pair and compute their productYou can write p? instead of opt(p) and p* instead of rep(p)  It seems a good idea to use these familiar operators, but they conflict with the ^^ operator. You have to add another set of parentheses, such as```scaladef term: Parser[Any] = factor ~ (("*" ~ factor)*) ^^ { ... }```For that reason, I prefer opt and rep.The tokens are required for parsing, but they can often be discarded after they have been matched. `The ~> and <~ operators are used to match and discard a token.` For example, `the result of "*" ~> factor is just the result of factor, not a value of the form "*" ~ f`. With that notation, we cansimplify the term function to```scaladef term = factor ~ rep("*" ~> factor) ^^ {  case f ~ r => f * r.product}def factor = number ^^ { _.toInt } | "(" ~> expr <~ ")"```Note that the “arrow tip” of `the ~> or <~ operator` points to the part that is retained.The rep method matches zero or more repetitions. Table 19–1 shows several variations of this combinator. The most commonly used among them is **repsep**. For example, a list of comma-separated numbers can be defined as```scaladef numberList = number ~ rep("," ~> number)```or more concisely as```scaladef numberList = repsep(number, ",")```Whenever an alternative p | q is parsed and p fails, the parser tries q on the same input. This **backtracking** can be inefficient.```scala  def expr: Parser[Any] = term ~! opt(("+" | "-") ~! expr)  def term: Parser[Any] = factor ~! rep("*" ~! factor)  def factor: Parser[Any] = "(" ~! expr ~! ")" | number````When p ~! q is evaluated and q fails, no other alternatives are tried in an enclosing |. For example, if factor finds a "(" and then expr doesn’t match, the parser won’t even try matching number.#### Left RecursionIf a parser function calls itself without first consuming some input, the recursion will never stop. Consider this function that is supposed to consume any sequence of ones:```scala  def ones: Parser[Any] = "1" ~ ones```Such a function is called **left-recursive**. To avoid the recursion, you can reformulate the grammar. Here are two alternatives:```scaladef ones: Parser[Any] = "1" ~ ones | "1"// ordef ones: Parser[Any] = rep1("1")```This problem occurs commonly in practice.#### Packrat ParsersA packrat parser uses an efficient parsing algorithm that caches previous parse results. This has two advantages:* Parse time is guaranteed to be proportional to the length of the input.* The parser can accept left-recursive grammars.In order to use packrat parsing in Scala, follow these steps:  1. Mix the PackratParsers trait into your parser.2. Use val or lazy val, not def, for each parser function. This is important because the parser caches these values, and it relies on them being identical. (A def would return a different value each time it is called.)3. Have each parser function return PackratParser[T] instead of Parser[T].4. Use a PackratReader and supply a parseAll method (which is annoyingly missing from the PackratParsers trait).  For example,```scalaclass OnesPackratParser extends RegexParsers with PackratParsers {  lazy val ones: PackratParser[Any] = ones ~ "1" | "1"  def parseAll[T](p: Parser[T], input: String) =    phrase(p)(new PackratReader(new CharSequenceReader(input)))}```Technically, a Parser[T] is a function with one argument, of type Reader[Elem], and a return value of type ParseResult[T].   The type Elem is an abstract type of the Parsers trait. The RegexParsers trait defines Elem as Char, and the StdTokenParsers trait defines Elem as Token.   A Reader[Elem] reads a sequence of Elem values (that is, characters or tokens) from some source and tracks their positions for error reporting.  When a Parser[T] is invoked on a reader, it returns an object of one of three subclasses of ParseResult[T]: Success[T], Failure, or Error.  An Error terminates the parser and anything that called it. It can arise in one of these circumstances:  * A parser p ~! q fails to match q.* A commit(p) fails.* The err(msg) combinator is encountered.A Failure simply arises from a failure to match; it normally triggers alternatives in an enclosing |.  A Success[T] has, most importantly, a result of type T. It also has a Reader[Elem] called next, containing the input beyond the match that is yet to be consumed.The | method combines two parsers. That is, if p and q are functions, then p | q is again a function. The combined function consumes a reader, say r. It calls p(r). If that call returns Success or Error, then that’s the return value of p | q. Otherwise, the return value is the result of q(r).Token-based parsers use a Reader[Token] instead of a Reader[Char]. The Token type is defined in the trait scala.util.parsing.combinator.token.Tokens. The StdTokens subtrait defines four types of tokens that one commonly finds when parsing a programming language:  * Identifier* Keyword* NumericLit* StringLitWhen you extend this parser, add any reserved words and special tokens to the lexical.reserved and lexical.delimiters sets:```scalaclass MyLanguageParser extends StandardTokenParser {  lexical.reserved += ("auto", "break", "case", "char", "const", ...)  lexical.delimiters += ("=", "<", "<=", ">", ">=", "==", "!=", ...)  // ...}```When the parser fails, the parseAll method returns a Failure result. Its msg property is an error message that you will want to display to the user. The next property is the Reader that points to the unconsumed input at the point of failure. You will want to display the line number and column, which are available as next.pos.line and next.pos.column.  Finally, next.first is the lexical element at which the failure occurred. If you use the RegexParsers trait, that element is a Char, which is not very useful for error reporting. But with a token parser, next.first is a token, which is worth reporting.Actors---Actors provide an alternative to the traditional lock-based architecture of concurrent programs. By avoiding locks and shared state, actors make it easier to design programs that work correctly, without deadlocks or race conditions. The Scala library provides a simple implementation of the actor model that we discuss in this chapter. More advanced actor libraries are available from other sources, such as Akka [http://akka.io][scala_Akka_1].* Extend the Actor class and provide an act method for each actor.* To send a message to an actor, use actor ! message.* `Message sending is asynchronous`: “send and forget.”* To receive messages, an actor calls receive or react, `usually in a loop`.* `The argument to receive/react is a block of case clauses (technically, a partial function)`.* `Actors should never share state. Always send data using messages`.* Don’t invoke methods on actors. Communicate by sending messages.* `Avoid synchronous messaging`—that is, unlink sending a message and waiting for a reply.* Actors can share threads by using react instead of receive, provided the control flow of the message handler is simple.* `It is OK to let actors crash, provided you have other actors that monitor their demise`. Use linking to set up monitoring relationships.[Back To Indexes](#indexes)  An actor is a class that extends the Actor trait. That trait has one abstract method, act. Override that method to specify the actor’s behavior.  Typically, the act method contains a message loop.   ```scalaimport scala.actors.Actorclass HiActor extends Actor {  def act() {    while (true) {      receive {        case "Hi" => println("Hello")      }    }  }}// To start an actorval actor1 = new HiActoractor1.start()```Now the act method of actor1 runs concurrently, and you can start sending it messages. The thread calling start continues executing.The act method is similar to the run method of the Runnable interface in Java. Like the run methods of different threads, `the act methods of different actors run concurrently. However, actors are optimized for reacting to messages, whereas threads can carry out arbitrary activities.`Sometimes, it is useful to create an actor on the fly, instead of defining a class. The Actor companion object has a method actor for creating and starting an actor:  ```scalaimport scala.actors.Actor._val actor2 = actor {  while (true) {    receive {      case "Hi" => println("Hello")    }  }}```Sometimes, an anonymous actor needs to send another actor a reference to itself. It is available as the **self** property.  To send a message, use the ! operator that is defined for actors:```scalaactor1 ! "Hi"```It is a good idea to use case classes for messages. That way, an actor can use pattern matching to process its messages.The messages that are sent to an actor are held in a “mailbox.” The receive method retrieves the next message from the mailbox and passes it to its argument, a partial function. For example, consider  ```scalareceive {  case Deposit(amount) => ...  case Withdraw(amount) => ...}```The argument of receive is```scala{  case Deposit(amount) => ...  case Withdraw(amount) => ...}```That block is converted to an object of type PartialFunction[Any, T], where T is the type of the result that is computed by the righthand sides of the case clauses. It is a “partial” function because it is only defined for arguments that match one of the case clauses.The receive method passes messages from the mailbox to that partial function.  If no message is available when receive is called, `the call blocks until a message arrives`.  `If none of the messages in the mailbox can be processed by the partial function, the call to receive also blocks until a matching message has been delivered`.It is possible for a mailbox to get filled up with messages that don’t match any of the case clauses. You can add a case _ clause to process arbitrary messages.The mailbox serializes the messages. `The actor runs in a single thread`. It first receives one message, then the next. You don’t have to worry about race conditions in the code of the actor. For example, suppose an actor updates a balance:  ```scalaclass AccountActor extends Actor {  private var balance = 0.0  def act() {    while (true) {      receive {        case Deposit(amount) => balance += amount        case Withdraw(amount) => balance -= amount        ...      }    }  }}```There is no danger of intermingling the increment and decrement.An actor can safely mutate its own data. But if it mutates data that is shared among actors, then race conditions can occur.`Don’t use a shared object from different actors unless you know that accessing it is threadsafe`. Ideally, actors should never access or mutate any state other than their own. However, Scala does not enforce such a policy.When a computation is divided among actors that concurrently work on parts of a problem, the results need to be gathered together. Actors could deposit results in a threadsafe data structure, such as a concurrent hash map, but the actor model discourages the use of shared data. Instead, an actor that has computed a result should send a message to another actor.  How does an actor know where to send the result? There are several design choices.  1. There may be a number of global actors. However, this does not scale to large numbers of actors.2. An actor may be constructed with references to one or more actors.3. The actor receives a message with a reference to another actor. It is common to provide an actor reference in a request, such as  ```scalaactor ! Compute(data, continuation)```Here continuation is another actor that should be called with the result of the computation.   4. The actor can return a message to the sender. The receive method sets the `sender field` to the sender of the current message.When an actor has a reference to another actor, it should only use that reference for sending messages, not for invoking methods. Not only does that violate the spirit of the actor model, but it can lead to race conditions—exactly the problem that actors were designed to avoid.#### ChannelsInstead of sharing references to actors in your application, you can share channels to the actors. This has two advantages.  1. Channels are typesafe—you can only send or receive messages of a particular type.2. You cannot accidentally invoke an actor’s method on a channel.A channel can be an OutputChannel (with a ! method) or an InputChannel (with a receive or react method). The Channel class extends both the OutputChannel and InputChannel traits.To construct a channel, you can supply an actor:```scalaval channel = new Channel[Int](someActor)```If you don’t supply a construction parameter, then the channel is tied to the currently executing actor.  Typically, you would tell an actor to send a result to an output channel.```scalacase class Compute(input: Seq[Int], result: OutputChannel[Int])class Computer extends Actor {  public void act() {    while (true) {      receive {        case Compute(input, out) => { val answer = ...; out ! answer }      }    }  }}actor {  val c = new Channel[Int]  val computeActor: Computer = ...  val input: Seq[Double] = ...  computeActor ! Compute(input, channel)  channel.receive {    case x => ... // x is known to be an Int  }}```Note that we call receive on the channel, not the actor itself. If you want to receive the response through the actor, match an instance of the ! case class instead, like this:  ```scalareceive {  case !(channel, x) => ...}```An actor can send a message and wait for a reply, by using the !? operator.   For example,  ```scalaval reply = account !? Deposit(1000)reply match {  case Balance(bal) => println("Current Balance: " + bal)}```For this to work, the recipient must return a message to the sender:  ```scalareceive {  case Deposit(amount) => { balance += amount; sender ! Balance(balance) }  ...}```The sender blocks until it receives the reply.  Instead of sender ! Balance(balance), you can write reply(Balance(balance)).Synchronous messages can easily lead to deadlocks. In general, it is best to avoid blocking calls inside an actor’s act method.In a robust system, you probably don’t want to wait forever for a reply. In that case, use the receiveWithin method to specify how many milliseconds you want to wait.  If no message is received within that time, you will instead receive the Actor.TIMEOUT object.  ```scalaactor {  worker ! Task(data, self)  receiveWithin(seconds * 1000) {    case Result(data) => ...    case TIMEOUT => log(...)  }}```Instead of waiting for the answer, you can opt to receive a future—an object that will yield a result when it becomes available.  Use the !! method:```scalaval replyFuture = account !! Deposit(1000)```The isSet method checks whether the result is available. To retrieve the result, use the function call notation:  ```scalaval reply = replyFuture()```This call blocks until the reply has been sent.Some programs contain so many actors that it would be expensive to create a separate thread for each of them. Could we run multiple actors in the same thread? Let’s assume that actors spend most of their time waiting for messages. Instead of having each of them block on a separate thread, we can have a single thread executing the message handling functions of multipleactors. This works, provided each message handling function only does a small amount of work before it waits for the next message.In Scala, you can do better. The react method takes a partial function and adds it to the mailbox, then exits. Suppose we have two nested react statements:  ```scalareact { // Partial function f1  case Withdraw(amount) =>  react { // Partial function f2    case Confirm() =>      println("Confirming " + amount)  }}```The first call to react associates f1 with the actor’s mailbox, and then exits. When a Withdraw message arrives, f1 is invoked. The partial function f1 also calls react. This call to react associates f2 with the actor’s mailbox; then it exits. When a Confirm message arrives, f2 is invoked.The second react might be in a separate function. Therefore, `react throws an exception in order to exit.`  Since react exits, you can’t simply place it in a while loop. Consider```scaladef act() {  while (true) {    react { // Partial function f1      case Withdraw(amount) => println("Withdrawing " + amount)    }  }}```When act is called, the call to react associates f1 with the mailbox, and then exits. When f1 is called, it handles the message.  However, f1 has no way of returning to the loop—it’s just a small function:```scala{ case Withdraw(amount) => println("Withdrawing " + amount) }```One way to fix this is to call act again in the message handler:```scaladef act() {  react { // Partial function f1    case Withdraw(amount) => {      println("Withdrawing " + amount)      act()    }  }}```This recursion doesn’t consume significant stack space. `Each call to react throws an exception that clears out the stack`.  It doesn’t seem quite fair to make each message handler responsible for keeping the loop going. There are several “control flow combinators” that produce the loops automatically.  The loop combinator makes an infinite loop:  ```scaladef act() {  loop {    react {      case Withdraw(amount) => process(amount)    }  }}```If you need a loop condition, use loopWhile:```scalaloopWhile(count < max) {  react {    ...  }}```The eventloop method makes a simpler version of an infinite loop around react, which only works as long as the partial function doesn’t call react again.```scaladef act() {  eventloop {    case Withdraw(amount) => println("Withdrawing " + amount)  }}```The act method of an actor starts executing when the actor’s start method is called. Typically, an actor then enters a loop such as  ```scaladef act() {  while (more w ork to do ) {    receive {      ...    }  }}```An actor terminates in one of the three cases:  1. The act method returns.2. The act method is terminated because of an exception.3. The actor calls the exit method.The exit method is a protected method. It must be called from a subclass of Actor. For example,  ```scalaval actor1 = actor {  while (true) {    receive {      case "Hi" => println("Hello")      case "Bye" => exit()    }  }}```When an actor terminates with an exception, then the exit reason is an instance of the UncaughtException case class#### Linking ActorsWhen you link two actors, each is notified if the other terminates. To establish the linkage, simply call the link method with a reference to the other actor.  ```scaladef act() {  link(master)  ...}```Links are bidirectional. For example, if a supervisor actor distributes work among several workers, then the supervisor should know if one of the workers dies, so that the work can be reassigned. Conversely, if the supervisor dies, the workers should know so they can stop working.  Even though links are bidirectional, the link method is not symmetrical. You cannot replace link(worker) with worker.link(self). The method must be called by the actor that requests the linkage.  By default, an actor terminates whenever a linked actor exits with a reason other than 'normal. In that case, the exit reason is set to the **linked** actor’s exit reason.  An actor can change this behavior by setting the trapExit property to true. Then, the actor receives a message of type Exit, holding the terminating actor and the exit reason.  ```scalaoverride def act() {  trapExit = true  link(worker)  while (...) {    receive {      ...      case Exit(linked, UncaughtException(_, _, _, _, cause)) => ...      case Exit(linked, reason) => ...    }  }}```When working with actors, it is normal to allow them to fail. Simply link each actor to a “supervisor” who will deal with failing actors, for example by reallocating their work or restarting them.  In a larger system, group your actors into zones, each with their own supervisor.  When an actor has terminated, it still has its internal state and mailbox. If you want to retrieve these messages, you can call restart on the terminated actor. Before doing that, you probably want to repair the internal state or set a flag indicating that the actor is now running in salvage mode. You also need to reestablish any links, since links are removed upon termination.#### Designing with ActorsYou have now seen the mechanics of working with actors, but knowing the rules doesn’t tell you how to structure your application. Here are a few tips:  1. Avoid shared state.   An actor should not access data outside its instance variables. Any data that it needs should be brought to it in messages. Beware of mutable state in messages. If an actor sends a reference to a mutable object to another, then both actors share this reference. If you must do this, then the sending actor should clear its copy of the reference immediately, thereby transferring the object to the receiving actor.2. Don’t call methods on actors.  If one actor invokes a method on another, you have the same synchronization issues that require locks in traditional concurrent programming. Consider using channels to avoid any such temptation.  3. Keep each actor simple.   Actor-based programs are easiest to understand if each actor does a simple job repeatedly—receiving work orders, computing an answer, and sending it on to the next actor.  4. Include contextual data in messages.  `An actor should be able to understand a message in isolation, without having to keep track of related messages`. For example, if you break your work up into n pieces, it is a good idea to specify that a particular work order is piece i of n.  5. Minimize replies to the sender.   Actors are not intended to be remote procedure calls. Your work should be distributed so that it flows through a network of actors that compute parts of an answer, then send them on to other actors that combine the parts.  6. Minimize blocking. When an actor blocks, it cannot receive any more messages, but the actors that send it messages won’t know about that. As a result, messages will accumulate in the blocking actor’s mailbox. For I/O activities, consider using nonblocking (or asynchronous) I/O, such as the asynchronous channels in Java. Avoid synchronous calls. They block, and may well lead to deadlocks.7. Use react when you can.   Actors that use react can share threads. You can always use react when the message handlers carry out a task and then exit.  8. Establish failure zones.  It is OK for an actor to fail, as long as it has designated another actor that will clean up. Group related actors into zones, and provide a supervisor for each zone. The supervisor should have the sole responsibility of managing failed actors.Implicits---Implicit conversions and implicit parameters are Scala’s power tools that do useful work behind the scenes.  * Implicit conversions are used to convert between types.* `You must import implicit conversions` so that they are in scope as single identifiers.* An implicit parameter list requests objects of a given type. They can be obtained from `implicit objects that are defined as single identifiers in scope`, or from the `companion object of the desired type`.* If an implicit parameter is a single-argument function, it is also used as an implicit conversion.* A context bound of a type parameter requires the existence of an implicit object of the given type.* If it is possible to locate an implicit object, this can serve as evidence that a type conversion is valid.[Back To Indexes](#indexes)  An implicit conversion function is a function with a single parameter that is declared with the implicit keyword. As the name suggests, such a function is automatically applied to convert values from one type to another.Here is a simple example. We want to convert integers n to fractions n / 1.```scalaimplicit def int2Fraction(n: Int) = Fraction(n, 1)```Now we can evaluate```scalaval result = 3 * Fraction(4, 5) // Calls int2Fraction(3)```You can give any name to the conversion function. I suggest that you stick with the source2target convention.Did you ever wish that a class had a method that its creator failed to provide? For example, wouldn’t it be nice if the java.io.File class had a read method for reading a file:```scalaval contents = new File("README").read```As a Java programmer, your only recourse is to petition Oracle Corporation to add that method. Good luck!In Scala, you can define an enriched type that provides what you want:```scalaclass RichFile(val from: File) {  def read = Source.fromFile(from.getPath).mkString}```Then, provide an implicit conversion to that type:```scala  implicit def file2RichFile(from: File) = new RichFile(from)```Now you can call read on a File object. It is implicitly converted to a RichFile.`Scala will consider the following implicit conversion functions`:  1. Implicit functions in the companion object of the source or target type2. Implicit functions that are in scope as a single identifier  For example, consider the int2Fraction function. We can place it into the Fraction companion object, and it will be available for converting fractions.Alternatively, let’s suppose we put it inside a FractionConversions object, which we define in the com.horstmann.impatient package. If you want to use the conversion, import the FractionConversions object, like this:  ```scalaimport com.horstmann.impatient.FractionConversions._```The following import would not be sufficient:  ```scalaimport com.horstmann.impatient.FractionConversions```In the REPL, type `:implicits` to see all implicits that have been imported from a source other than Predef, or `:implicits -v` to see all implicits.You can even select the specific conversions that you want. Suppose you have a second conversion  ```scalaobject FractionConversions {  ...  implicit def fraction2Double(f: Fraction) = f.num * 1.0 / f.den}```If you prefer this conversion over int2Fraction, you can import it:```scalaimport com.horstmann.impatient.FractionConversions.fraction2Doubleval result = 3 * Fraction(4, 5) // result is 2.4```You can also exclude a specific conversion if it causes you trouble:```scalaimport com.horstmann.impatient.FractionConversions.{fraction2Double => _, _}// Imports everything but fraction2Double```On the other hand, there are three situations when an implicit conversion is not attempted:  * No implicit conversion is used if the code compiles without it. For example, if a * b compiles, the compiler won’t try a * convert(b) or convert(a) * b.* The compiler will never attempt multiple conversions, such as convert1(convert2(a)) * b.* Ambiguous conversions are an error. For example, if both convert1(a) * b and convert2(a) * b are valid, the compiler will report an error.The ambiguity rule only holds for the object on which the conversion is attempted. Consider the case```scalaFraction(3, 4) * 5```It is not an ambiguity that both```scalaFraction(3, 4) * int2Fraction(5)```and```scalafraction2Double(Fraction(3, 4)) * 5```are valid. The first conversion wins over the second, since it does not require modification of the object to which the * method is applied.If you want to find out which implicit conversion the compiler uses, compile your program as```scalascalac -Xprint:typer MyProg.scala```You will see the source after implicit conversions have been added.#### Implicit ParametersA function or method can have a parameter list that is marked implicit. In that case, the compiler will look for default values to supply with the function call. Here is a simple example:```scalacase class Delimiters(left: String, right: String)def quote(what: String)(implicit delims: Delimiters) =  delims.left + what + delims.right```You can call the quote method with an explicit Delimiters object, like this:```scalaquote("Bonjour le monde")(Delimiters("«", "»")) // Returns «Bonjour le monde»```You can also omit the implicit parameter list:  ```scalaquote("Bonjour le monde")```In that case, the compiler will look for an implicit value of type Delimiters. This must be a value that is declared as implicit. The compiler looks for such an object in two places:  * Among all val and def of the desired type that are in scope as a single identifier.* In the companion object of a type that is associated with the desired type. Associated types include the desired type itself, and, if it is a parameterized type, its type parameters.In our example, it is useful to make an object, such as```scalaobject FrenchPunctuation {  implicit val quoteDelimiters = Delimiters("«", "»")  ...}```Then one imports all values from the object:```scalaimport FrenchPunctuation._```or just the specific value:```scalaimport FrenchPunctuation.quoteDelimiters```Now the French delimiters are supplied implicitly to the quote function.An **implicit function parameter** is also usable as an implicit conversion. To understand the significance, consider first this simple generic function:```scaladef smaller[T](a: T, b: T) = if (a < b) a else b // Not quite```That doesn’t actually work. The compiler won’t accept the function because it doesn’t know that a and b belong to a type with a < operator.We can supply a conversion function for that purpose:  ```scaladef smaller[T](a: T, b: T)(implicit order: T => Ordered[T])  = if (order(a) < b) a else b```Since the Ordered[T] trait has a < operator that consumes a T, this version is correct.  As it happens, this is such a common situation that the Predef object defines implicit values of type T => Ordered[T] for a large number of types, including all types that already implement Ordered[T] or Comparable[T].Here, finally, is the point. Look again at  ```scaladef smaller[T](a: T, b: T)(implicit order: T => Ordered[T])```Note that order is a function with a single parameter, is tagged implicit, and has a name that is a single identifier. Therefore, it is an implicit conversion, in addition to being an implicit parameter. So, we can omit the call to order in the body of the function:  ```scaladef smaller[T](a: T, b: T)(implicit order: T => Ordered[T])  = if (a < b) a else b // Calls order(a) < b if a doesn't have a < operator```#### Context BoundsA type parameter can have a context bound of the form T : M, where M is another generic type. It requires that there is an implicit value of type M[T] in scope. For example,  ```scalaclass Pair[T : Ordering]```requires that there is an implicit value of type Ordering[T]. That implicit value can then be used in the methods of the class.   Consider this example:  ```scalaclass Pair[T : Ordering](val first: T, val second: T) {  def smaller(implicit ord: Ordering[T]) =    if (ord.compare(first, second) < 0) first else second}```If we form a new Pair(40, 2), then the compiler infers that we want a Pair[Int]. Since there is an implicit value of type Ordering[Int] in the Predef scope, Int fulfills the context bound. That ordering becomes a field of the class, and it is passed to the methods that need it.  Alternatively, you can take advantage of the fact that the Ordered trait defines an implicit conversion from Ordering to Ordered. If youimport that conversion, you can use relational operators:```scalaclass Pair[T : Ordering](val first: T, val second: T) {  def smaller = {    import Ordered._;    if (first < second) first else second  }}```These are just minor variations; the important point is that you can instantiate Pair[T] whenever there is an implicit value of typeOrdering[T]. For example, if you want a Pair[Point], arrange for an implicit Ordering[Point] value:  ```scalaimplicit object PointOrdering extends Ordering[Point] {  def compare(a: Point, b: Point) = ...}```In Chapter 17, you saw the type constraints  T =:= U  T <:< U  T <%< U  The constraints test whether T equals U, is a subtype of U, or is view-convertible to U. To use such a type constraint, you supply animplicit parameter, such as```scaladef firstLast[A, C](it: C)(implicit ev: C <:< Iterable[A]) =  (it.head, it.last)```The =:=, <:<, and <%< are classes with implicit values, defined in the Predef object.  We call ev an “evidence object”—its existence is evidence of the fact that, in this case, String is a subtype of AnyRef.To test whether a generic implicit object exists, you can call the implicitly function in the REPL. For example, type```scalaimplicitly[String <:< AnyRef]```in the REPL, and you get a result (which happens to be a function). But implicitly[AnyRef <:< String] fails with an error message.#### The @implicitNotFound AnnotationThe @implicitNotFound annotation raises an error message when the compiler cannot construct an implicit parameter of the annotated type. The intent is to give a useful error message to the programmer. For example, the <:< class is annotated as  ```scala@implicitNotFound(msg = "Cannot prove that ${From} <:< ${To}.")abstract class <:<[-From, +To] extends Function1[From, To]``````scalatrait Builder[-E, +To] {  def +=(e: E): Unit  def result(): To}trait CanBuildFrom[-From, -E, +To] {  def apply(): Builder[E, To]}```The CanBuildFrom[From, E, To] trait provides evidence that it is possible to create a collection of type To, holding values of type E, that is compatible with type From.  `Each collection provides an implicit CanBuildFrom object in its companion object`Consider the map method. Simplifying slightly, map is a method of Iterable[A, Repr] with the following implementation:  ```scaladef map[B, That](f : (A) => B)(implicit bf: CanBuildFrom[Repr, B, That]): That = {  val builder = bf()  val iter = iterator()  while (iter.hasNext) builder += f(iter.next())  builder.result}```Here, Repr is the “representation type.” That parameter will enable us to select appropriate builder factories for unusual collections such as Range or String.Here is a simplified Range class that provides a Buffer as builder:  ```scalaclass Range(val low: Int, val high: Int) extends Iterable[Int, Range] {  def iterator() = ...}object Range {  implicit def canBuildFrom[E : Manifest] = new CanBuildFrom[Range, E, Buffer[E]] {    def apply() = new Buffer[E]  }}```Now consider a call Range(1, 10).map(f). That method needs an implicit bf: CanBuildFrom[Repr, B, That]. Since Repr is Range, the associated types are CanBuildFrom, Range, B, and the unknown That. The Range object yields a match by calling its canBuildFrom[B] method, which returns a CanBuildFrom[Range, B, Buffer[B]]. That object is bf, and its apply method yields a Buffer[B] for building the result.Delimited Continuations---Continuations are a powerful construct that allows you to implement control flow mechanisms other than the familiar branches, loops, function calls, and exceptions. For example, you can jump back into a prior computation or reorder the execution of parts of a program. These capabilities can be mind-bending; `they are not intended for application programmers, but library implementors` can harness the power of continuations and make them available to library users in a transparent way.  * A continuation lets you go back to a previous point in a program.* You capture a continuation in a shift block.* A continuation function extends until the end of the enclosing reset block.* A continuation is the “rest of the computation” from the expression containing the shift to the end of the enclosing reset, with the shift replaced by a “hole.”* When you call a continuation with an argument, the “hole” is set to the argument.* Code containing shift expressions is rewritten in “continuation-passing style,” or CPS, up to the enclosing reset.* A method containing a shift without a reset must be annotated with a CPS annotation.* Continuations can be used to turn a recursive visit of a tree structure into an iteration.* Continuations can undo the “inversion of control” in a web or GUI application.First, you need to capture a continuation, using the shift construct. Inside the shift, you have to spell out what you want to do with the continuation when it is handed to you. Normally, you want to save it for later use.```scalavar cont: (Unit => Unit) = nullreset {  ...  shift { k: (Unit => Unit) =>  // Continuation passed to shift    cont = k  // Save for later use  } // Calling cont starts here . . .  ...} // . . . and ends here```Here, the continuation is a function with no arguments and no return value (or, strictly speaking, with an argument and return value of type Unit). We will later see continuations that can have an argument and a return value.  To jump back to the point of the shift, you invoke the continuation, simply by calling the cont method.  In Scala, a continuation is delimited—it extends only up to a given boundary. The boundary is marked by reset { ... }:When you call cont, execution starts at the shift and extends until the bounds of the reset block.Here is a complete example. We read a file and capture the continuation.  ```scalavar cont: (Unit => Unit) = nullvar filename = "myfile.txt"var contents = ""reset {  while (contents == "") {    try {      contents = scala.io.Source.fromFile(filename, "UTF-8").mkString    } catch { case _ => }    shift { k: (Unit => Unit) =>      cont = k    }  }}// To retry, just invoke the continuation:if (contents == "") {  print("Try another filename: ");  filename = readLine()  cont() // Go back to the shift} println(contents)```The flow of control in reset/shift is a bit confusing because they serve double duty—to define the continuation function and to capture it.  `When you call reset`, its body executes. When encountering a shift, the body of the shift is called with the continuation function as argument. When the shift has completed, `execution immediately jumps to the end of the enclosing reset`. Consider this code:  ```scalavar cont : (Unit => Unit) = nullreset {  println("Before shift")  shift { k: (Unit => Unit) => {      cont = k      println("Inside shift") // Jumps to end of reset    }  }  println("After shift")} println("After reset")cont()```When executing reset, the code prints    Before shift    Inside shift  Then it exits the reset block and prints    After reset  Finally, when calling cont, the execution jumps back into the reset block and prints    After shift  Note that the code before the shift is not a part of the continuation. The continuation starts with the expression containing the shift (which becomes the “hole”) and extends to the end of the reset. In this case, the continuation is  ```scala□: Unit => □; println("After shift")```The cont function has parameter Unit, and the hole is simply replaced with ().To understand exactly what a continuation captures, it is useful to think of the shift block as a “hole” inside the reset block. When you invoke the continuation, you can pass a value into the hole, and the computation runs as if the shift had that value. Consider this artificial example:  ```scalavar cont : (Int => Double) = nullreset {  0.5 * shift { k : (Int => Double) => cont = k } + 1}```Replace the shift with a “hole,” and you get```scalareset {  0.5 * □ + 1}```When you call cont(3), the hole gets filled with the value 3, and the code inside reset yields 2.5.  In other words, cont is simply the function x: Int => 0.5 * x + 1.  The continuation has type Int => Double because we fill an Int into the hole and compute a Double.Both reset and shift are methods with type parameters, reset[B, C] and shift[A, B, C]. The following “cheat sheet” shows how thetypes are inferred.```scalareset {  before  shift { k: (A => B) => // Infer A and B from here    inside // Type C  } // "Hole" has type A  after // Must yield a value of type B}```* A is the type of the argument of the continuation—the type of the value that is “put in the hole.”   * B is the return type of the continuation—the type of the value that is returned when one invokes the continuation. * C is the expected type of the reset expression—that is, the type of the value returned from the shift.If it is possible for the reset to return a value of type B or C (because of a branch or loop), then B must be a subtype of C.---[scala_inheritance_hierarchy_img_1]:/resources/img/java/scala_inheritance_hierarchy_1.png "scala_inheritance_hierarchy_1"[scala_collection_hierarchy_img_1]:/resources/img/java/scala_collection_hierarchy_1.png "scala_collection_hierarchy_1"[scala_collection_hierarchy_immutable_img_1]:/resources/img/java/scala_collection_hierarchy_immutable_1.png "scala_collection_hierarchy_immutable_1"[scala_collection_binary_operation_img_1]:/resources/img/java/scala_collection_binary_operation_1.png "scala_collection_binary_operation_1"[scala_collection_binary_operation_img_2]:/resources/img/java/scala_collection_binary_operation_2.png "scala_collection_binary_operation_2"[scala_xml_node_types_img_1]:/resources/img/java/scala_xml_node_types_1.png "scala_xml_node_types_1"[scala_Akka_1]:http://akka.io "Akka"